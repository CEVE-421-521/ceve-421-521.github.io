[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "CEVE 421/521 Schedule",
    "section": "",
    "text": "Reading\n\n\n\nA subset of readings listed here will likely be assigned. Check the page for each reading to see discussion questions.\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Topic\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nWeek\n\n\nTopic\n\n\nDate\n\n\nCategory\n\n\n\n\n\n\n1\n\n\nWelcome to CEVE 421/521!\n\n\nMon., Jan. 8\n\n\nLecture\n\n\n\n\n1\n\n\nWeek 1 readings\n\n\nWed., Jan. 10\n\n\nReading\n\n\n\n\n1\n\n\nLab 1: Software Installation\n\n\nFri., Jan. 12\n\n\nLab\n\n\n\n\n2\n\n\nThe Science of Climate Hazard\n\n\nWed., Jan. 17\n\n\nLecture\n\n\n\n\n2\n\n\nWeek 2 readings\n\n\nWed., Jan. 17\n\n\nReading\n\n\n\n\n2\n\n\nLab 2: Julia Quickstart\n\n\nFri., Jan. 19\n\n\nLab\n\n\n\n\n3\n\n\nVulnerability, Exposure, and Impacts\n\n\nMon., Jan. 22\n\n\nLecture\n\n\n\n\n3\n\n\nReadings for Week 3\n\n\nWed., Jan. 24\n\n\nReading\n\n\n\n\n3\n\n\nLab 3: Depth-Damage Models\n\n\nFri., Jan. 26\n\n\nLab\n\n\n\n\n4\n\n\nClimate Risks to Complex Sytems\n\n\nMon., Jan. 29\n\n\nLecture\n\n\n\n\n4\n\n\nExam 1\n\n\nFri., Feb. 2\n\n\nExam\n\n\n\n\n5\n\n\nCost-Benefit Analysis\n\n\nMon., Feb. 5\n\n\nLecture\n\n\n\n\n5\n\n\nCost-Benefit Analysis II\n\n\nWed., Feb. 7\n\n\nLecture\n\n\n\n\n5\n\n\nLab 4: House Elevation NPV Analysis\n\n\nThu., Feb. 8\n\n\nLab\n\n\n\n\n6\n\n\nScenario Analysis\n\n\nMon., Feb. 12\n\n\nLecture\n\n\n\n\n6\n\n\nReadings for Week 6\n\n\nWed., Feb. 14\n\n\nReading\n\n\n\n\n6\n\n\nLab 5: Sea-Level Rise\n\n\nFri., Feb. 16\n\n\nLab\n\n\n\n\n7\n\n\nPolicy Search and Optimization\n\n\nMon., Feb. 19\n\n\nLecture\n\n\n\n\n7\n\n\nReadings for Week 7\n\n\nWed., Feb. 21\n\n\nReading\n\n\n\n\n7\n\n\nLab 6: Policy Search\n\n\nFri., Feb. 23\n\n\nLab\n\n\n\n\n8\n\n\nMultiobjective Policy Search and Optimization\n\n\nMon., Feb. 26\n\n\nLecture\n\n\n\n\n8\n\n\nReadings for Week 8\n\n\nWed., Feb. 28\n\n\nReading\n\n\n\n\n8\n\n\nLab 7: Multiobjective Optimization\n\n\nFri., Mar. 1\n\n\nLab\n\n\n\n\n9\n\n\nSequential Decision Problems\n\n\nMon., Mar. 4\n\n\nLecture\n\n\n\n\n9\n\n\nReadings for Week 9\n\n\nWed., Mar. 6\n\n\nReading\n\n\n\n\n9\n\n\nLab 8: Parking Garage Case Study\n\n\nFri., Mar. 8\n\n\nLab\n\n\n\n\n10\n\n\nRobustness\n\n\nMon., Mar. 18\n\n\nLecture\n\n\n\n\n10\n\n\nReadings for Week 10\n\n\nWed., Mar. 20\n\n\nReading\n\n\n\n\n10\n\n\nExam 2\n\n\nFri., Mar. 22\n\n\nExam\n\n\n\n\n11\n\n\nDeep Uncertainty\n\n\nMon., Mar. 25\n\n\nLecture\n\n\n\n\n11\n\n\nReadings for Week 11\n\n\nWed., Mar. 27\n\n\nReading\n\n\n\n\n11\n\n\nLab 9: The Lake Problem\n\n\nFri., Mar. 29\n\n\nLab\n\n\n\n\n12\n\n\nEquity and Justice\n\n\nMon., Apr. 1\n\n\nLecture\n\n\n\n\n12\n\n\nReadings for Week 12\n\n\nWed., Apr. 3\n\n\nReading\n\n\n\n\n13\n\n\nFinancial and Systemic Risks\n\n\nWed., Apr. 10\n\n\nLecture\n\n\n\n\n13\n\n\nReadings for Week 13\n\n\nWed., Apr. 10\n\n\nReading\n\n\n\n\n14\n\n\nReflections\n\n\nMon., Apr. 15\n\n\nLecture\n\n\n\n\n14\n\n\nReadings for Week 14\n\n\nWed., Apr. 17\n\n\nReading\n\n\n\n\n14\n\n\nExam 3\n\n\nFri., Apr. 19\n\n\nExam\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "lectures/05-bca2.html",
    "href": "lectures/05-bca2.html",
    "title": "Cost-Benefit Analysis II",
    "section": "",
    "text": "Here’s a brief recap, with a few additional points.\n\nDefining “goodness” of different outcomes\n\nWe need a utility / objective / loss function to compare different outcomes: \\(u(a, \\mathbf{s}): \\mathcal{A} \\times \\mathcal{S} \\to \\mathbb{R}\\) where \\(\\mathcal{A}\\) is the set of actions and \\(\\mathcal{S}\\) is the set of states of the world.\nMathematically and practically, we can define “goodness” however we want! We are free to choose our metric of goodness to compare different decisions.\nUtility: “rational” people make decisions as though maximizing some internal, invisible utility function. This leads to useful insights from the field of economics.\n\nKey insight: decreasing marginal utility. When you have a lot of most things, getting a little bit more is not as valuable as when you have very little of it. For example, $1,000 is worth a lot more to a poor person than to a rich person. 100 gallons of water are more valuable to someone who walks 5 miles a day carrying water than to someone who has a tap in their kitchen.\nWe should be skeptical of utility as a framework for predicting human behavior, but that’s not necessarily our goal.\n\nSocial welfare: even if you believe everyone has a utility function, it turns out that there’s not a a single “right” way to combine many peoples’ utility functions into a single number describing social welfare.\nCash flow: often, we put things into dollar terms. This is not because we think money is the most important thing. Instead, we can look at opportunity costs to try to put dollar values on things that are hard to value. For example, if we can protect one square mile of pristine wetland for $1 million, then arguably we shouldn’t spend more than that to protect another square mile of wetland. (But are they really substitutes?)\nDiscounted cash flow: a dollar today is worth more than a dollar tomorrow. To compute the net present value (NPV) of a future cost or benefit, we discount it to the present using a discount rate \\(\\gamma\\). If we define \\(\\gamma = 2\\%\\) then a dollar in 10 years is worth \\((1 - \\gamma)^{10} =  \\$0.82\\) today.\n\nCost-benefit analysis under uncertainty\n\nMany analyses in the real world choose a single “best guess” or “representative” state of the world (often referred to as scenario or similar). For example, for analyzing the costs and benefits of expanding a water resource system, a hypothetical water utility in Houston might use:\n\nprojections of future population / demand from a regional water plan\na single projected climate scenario\na single assumed set of regulations on water quality\ncurrent prices of building / operating water infrastructure\n\nHowever, many decisions that perform well under one scenario perform poorly under another. For example, a water utility might choose to build a new reservoir to meet future demand, but if the future is drier than expected, the reservoir might not fill up. Or, if the future is wetter than expected, the reservoir might fill up too much and flood people’s homes. (This will be a theme of the course!)\nA better approach is to allow uncertainty by computing expected utility / objective / loss / metrics. This is a weighted average of the utility under different states of the world, where the weights are the probabilities of those states of the world.\n\n\\(\\mathbb{E}_\\mathbf{s} \\left[ u(a, \\mathbf{s}) \\right] = \\int p(\\mathbf{s}) u(a, \\mathbf{s}) d\\mathbf{s}\\) where \\(p(\\mathbf{s})\\) is the probability density of SOW \\(\\mathbf{s}\\).\nThis requires defining a probability distribution over states of the world."
  },
  {
    "objectID": "lectures/05-bca2.html#proposed-solutions",
    "href": "lectures/05-bca2.html#proposed-solutions",
    "title": "Cost-Benefit Analysis II",
    "section": "Proposed solutions",
    "text": "Proposed solutions\n\nUse a very low discount rate\n\nThis places more weight on outcomes far in the future\nHowever, this can also lead to irrational conclusions. For example,\n\nUncertain discount rate\n\n“Using an investment- or a consumption-based approach will require human judgment about the appropriate models to use to capture uncertainty about future discount rates” (Arrow et al., 2013)\nThis is equivalent to declining discount rate – as you go farther out, your NPV is dominated by the lower discount rates.\nYou still need to"
  },
  {
    "objectID": "readings/week-12-reading.html",
    "href": "readings/week-12-reading.html",
    "title": "Readings for Week 12",
    "section": "",
    "text": "Discussion questions will be posted here.\n\n\n\nAssigned reading will be drawn from:\n\nPollack et al. (2023)\nFletcher et al. (2022)\n\n\n\n\n\nReferences\n\nFletcher, S., Hadjimichael, A., Quinn, J., Osman, K., Giuliani, M., Gold, D., et al. (2022). Equity in Water Resources Planning: A Path Forward for Decision Support Modelers. Journal of Water Resources Planning and Management, 148(7), 02522005. https://doi.org/10.1061/(ASCE)WR.1943-5452.0001573\n\n\nPollack, A., Helgeson, C., Kousky, C., & Keller, K. (2023, September 15). Transparency on underlying values is needed for useful equity measurements. https://doi.org/10.31219/osf.io/kvyxr"
  },
  {
    "objectID": "readings/week-02-reading.html",
    "href": "readings/week-02-reading.html",
    "title": "Week 2 readings",
    "section": "",
    "text": "As before, you are encouraged to use Zotero to manage your references (Zotero has great tools for highlighting and annotating PDFs, among other cool features. It’s also open source so your annotations aren’t locked into a proprietary system).\n\n\n\n\nSeneviratne et al. (2021):\n\nRead the Executive Summary\nRead the Introduction (section 11.1)\nRead the Data and Methods (section 11.2)\nRead one additional subsection (11.3, 11.4, …, or 11.8)\nIf you’re adding this to Zotero, you may find the IPCC-Bibtex project helpful.\n\nRead all of Lall et al. (2018) (pp. 147-157)\nAs you’re reading along, please post any questions you have (clarification, topics you didn’t follow, etc.) to Canvas discussions.\nPrepare a two minute summary of key points from the “one additional subsection” that you read from Seneviratne et al. (2021). Be prepared to share your summary with the class.\nBe prepared to answer basic questions from the readings (focus on the executive summaries)"
  },
  {
    "objectID": "readings/week-02-reading.html#assigned-readings",
    "href": "readings/week-02-reading.html#assigned-readings",
    "title": "Week 2 readings",
    "section": "",
    "text": "As before, you are encouraged to use Zotero to manage your references (Zotero has great tools for highlighting and annotating PDFs, among other cool features. It’s also open source so your annotations aren’t locked into a proprietary system).\n\n\n\n\nSeneviratne et al. (2021):\n\nRead the Executive Summary\nRead the Introduction (section 11.1)\nRead the Data and Methods (section 11.2)\nRead one additional subsection (11.3, 11.4, …, or 11.8)\nIf you’re adding this to Zotero, you may find the IPCC-Bibtex project helpful.\n\nRead all of Lall et al. (2018) (pp. 147-157)\nAs you’re reading along, please post any questions you have (clarification, topics you didn’t follow, etc.) to Canvas discussions.\nPrepare a two minute summary of key points from the “one additional subsection” that you read from Seneviratne et al. (2021). Be prepared to share your summary with the class.\nBe prepared to answer basic questions from the readings (focus on the executive summaries)"
  },
  {
    "objectID": "readings/week-02-reading.html#discussion-questions",
    "href": "readings/week-02-reading.html#discussion-questions",
    "title": "Week 2 readings",
    "section": "Discussion questions",
    "text": "Discussion questions\n\nThink about one impact of climate change you were surprised to learn about and one hazard that is less of a concern than you thought it was.\nWhat are some of the challenges of using climate models to predict future climate? What are some of the challenges of using climate models to predict future impacts of climate change?\nWhat are some of the challenges of using observations to understand future climate? What are some of the challenges of using models to understand future impacts of climate change?"
  },
  {
    "objectID": "readings/week-08-reading.html",
    "href": "readings/week-08-reading.html",
    "title": "Readings for Week 8",
    "section": "",
    "text": "Discussion questions will be posted here.\n\n\n\nAssigned reading will be drawn from:\n\nZarekarizi et al. (2020)\n\n\n\n\n\nReferences\n\nZarekarizi, M., Srikrishnan, V., & Keller, K. (2020). Neglecting uncertainties biases house-elevation decisions to manage riverine flood risks. Nature Communications, 11(1, 1), 5361. https://doi.org/10.1038/s41467-020-19188-9"
  },
  {
    "objectID": "readings/week-11-reading.html",
    "href": "readings/week-11-reading.html",
    "title": "Readings for Week 11",
    "section": "",
    "text": "Discussion questions will be posted here.\n\n\n\nAssigned reading will be drawn from:\n\nSchneider (2002)\nLempert & Schlesinger (2000)\nOreskes et al. (1994)\n\n\n\n\n\nReferences\n\nLempert, R. J., & Schlesinger, M. E. (2000). Robust strategies for abating climate change. Climatic Change, 45(3-4), 387–401. https://doi.org/10.1023/A:1005698407365\n\n\nOreskes, N., Shrader-Frechette, K., & Belitz, K. (1994). Verification, validation, and confirmation of numerical models in the Earth sciences. Science. https://doi.org/10.1126/science.263.5147.641\n\n\nSchneider, S. H. (2002). Can we estimate the likelihood of climatic changes at 2100? Climatic Change, 52(4), 441–451. https://doi.org/http://dx.doi.org/10.1023/A:1014276210717"
  },
  {
    "objectID": "readings/week-06-reading.html",
    "href": "readings/week-06-reading.html",
    "title": "Readings for Week 6",
    "section": "",
    "text": "Discussion questions will be posted here.\n\n\n\nAssigned reading will be drawn from:\n\nBankes (1993)\n\n\n\n\n\nReferences\n\nBankes, S. (1993). Exploratory modeling for policy analysis. Operations Research, 41(3), 435–449. https://doi.org/c7rgcr"
  },
  {
    "objectID": "readings/week-10-reading.html",
    "href": "readings/week-10-reading.html",
    "title": "Readings for Week 10",
    "section": "",
    "text": "Discussion questions will be posted here.\n\n\n\nAssigned reading will be drawn from:\n\nHerman et al. (2015)\nMcPhail et al. (2019)\n\n\n\n\n\nReferences\n\nHerman, J. D., Reed, P. M., Zeff, H. B., & Characklis, G. W. (2015). How should robustness be defined for water systems planning under change? Journal of Water Resources Planning and Management, 141(10), 04015012. https://doi.org/10.1061/(asce)wr.1943-5452.0000509\n\n\nMcPhail, C., Maier, H. R., Kwakkel, J. H., Giuliani, M., Castelletti, A., & Westra, S. (2019). Robustness metrics: How are they calculated, when should they be used and why do they give different results? Earth’s Future, 169–191. https://doi.org/10.1002/2017ef000649"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CEVE 421/521: Climate Risk Management",
    "section": "",
    "text": "This is the course website for the Spring 2024 edition of CEVE 421/521, Climate Risk Management, taught at Rice University by James Doss-Gollin.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "CEVE 421/521: Climate Risk Management",
    "section": "Course Information",
    "text": "Course Information\nClimate variability and change pose threats to lives and livelihoods. These climate risks can be managed through the design and operation of infrastructure systems, as well as through disaster response and recovery. Decisions about how to develop and choose risk management strategies are often based on pure vibes, but occasionally rigorous quantitative analyses that make use of scientific information can inform them (we will focus on these cases). These analyses involve integrating knowledge from multiple disciplines to balance competing goals (objectives) under uncertainty.\nIn this course, you will learn climate science, uncertainty quantification, and decision analysis methods to support climate risk management. You will be assigned readings for every class that cover both methods and applications, and will work collaboratively to implement key concepts through programming problem sets. Active class participation is required. Methods covered include scenario analysis, exploratory modeling, cost-benefit analysis, single- and multi-objective policy search, reinforcement learning, deep uncertainty, robust decision making, and equitable decision making.\nFor additional information, see the syllabus.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "CEVE 421/521: Climate Risk Management",
    "section": "Instructor",
    "text": "Instructor\nDr. James Doss-Gollin is an assistant professor of Civil and Environmental Engineering at Rice University. His research integrates Earth science, data science, and decision science to address challenges in climate risk management, water resources, and energy system resilience. He also teaches CEVE 543 (Data Science for Climate Hazards).",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#software-tools",
    "href": "index.html#software-tools",
    "title": "CEVE 421/521: Climate Risk Management",
    "section": "Software Tools",
    "text": "Software Tools\n\nThis course will use the Julia programming language. Julia is a modern, free, open source language designed for scientific computing.\nNo prior knowledge of Julia is expected, but some exposure to programming is strongly encouraged.\nAssignments will be distributed using GitHub Classroom.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "CEVE 421/521: Climate Risk Management",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThe layout for this site was inspired by and draws from Vivek Srikrishnan’s Environmental Systems Analysis course at Cornell, STA 210 at Duke University, and Andrew Heiss’s course materials at Georgia State. It builds heavily from my data science for climate hazard assessment course, CEVE 543.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "labs/lab-02/index.html",
    "href": "labs/lab-02/index.html",
    "title": "Lab 2: Julia Quickstart",
    "section": "",
    "text": "In this lab we will learn how to work with tabular data in Julia. Specifically, you will get some experience using:\n\nDataFrames.jl to store tabular data as a DataFrame\nCSV.jl to read CSV files and convert them to DataFrames\nDataFramesMeta.jl to manipulate DataFrames\nPlots.jl and StatsPlots.jl to create visualizations\n\nFor those of you who took CEVE 543, you’ll find most of this familiar! If you find this challenging (e.g., if you’re new to programming) please look at the Resources page which has links to tutorials that you can use to get up to speed. Some of you will work extra hard this week, and some of you will have an easier week.\n\n\nIn this repository you will find two files.\n\nindex.qmd is the source code for the rendered document on the course website that you may be looking at now. That’s this file!\ntemplate.qmd is the template for your lab submission. You should edit it directly.\n\n\n\n\nAs with Lab 01, you should:\n\npush your final code to GitHub (I’ll be able to see it via GitHub classroom)\nsubmit your rendered PDF or DOCX file to Canvas"
  },
  {
    "objectID": "labs/lab-02/index.html#this-repository",
    "href": "labs/lab-02/index.html#this-repository",
    "title": "Lab 2: Julia Quickstart",
    "section": "",
    "text": "In this repository you will find two files.\n\nindex.qmd is the source code for the rendered document on the course website that you may be looking at now. That’s this file!\ntemplate.qmd is the template for your lab submission. You should edit it directly."
  },
  {
    "objectID": "labs/lab-02/index.html#submission",
    "href": "labs/lab-02/index.html#submission",
    "title": "Lab 2: Julia Quickstart",
    "section": "",
    "text": "As with Lab 01, you should:\n\npush your final code to GitHub (I’ll be able to see it via GitHub classroom)\nsubmit your rendered PDF or DOCX file to Canvas"
  },
  {
    "objectID": "labs/lab-02/index.html#clone-the-repository",
    "href": "labs/lab-02/index.html#clone-the-repository",
    "title": "Lab 2: Julia Quickstart",
    "section": "Clone the repository",
    "text": "Clone the repository\nFirst, you’ll need to clone this repository to your computer. As with Lab 01, I recommend to use GitHub Desktop or the built-in Git support in VS Code. Remember to use the link from Canvas (classroom.github.com/...).\nNext, open the repository in VS Code (you can do this directly from GitHub desktop if you’d like). All instructions from here assume you’re in the root directory of the repository."
  },
  {
    "objectID": "labs/lab-02/index.html#install-required-packages",
    "href": "labs/lab-02/index.html#install-required-packages",
    "title": "Lab 2: Julia Quickstart",
    "section": "Install required packages",
    "text": "Install required packages\nAs we saw in Lab 01, Julia is a modular language with code in packages. Compared to a language like Python, the packages in Julia typically have a narrower scope (for example, instead of a single Pandas package that does everything, there are separate packages for reading CSV files, defining dataframes, using clear syntax for data manipulation, etc.). When we’re working with a new lab, we’ll need to first install the packages we need.\n\nOpen the command palette and select Julia: Start REPL\nIn the Julia REPL, type ] to enter package manager mode\nType activate . to activate the project environment\nType instantiate to install the packages listed in the Project.toml file. This may take a few minutes.1"
  },
  {
    "objectID": "labs/lab-02/index.html#rendering-and-previewing",
    "href": "labs/lab-02/index.html#rendering-and-previewing",
    "title": "Lab 2: Julia Quickstart",
    "section": "Rendering and previewing",
    "text": "Rendering and previewing\nAs we saw in Lab 01, Quarto lets you convert a text file into an output. We’ve seen PDF, DOCX, and HTML (website) outputs, but there are other options as well.\nThere are many valid workflows, but my favorite is often to preview the document in VS Code while I’m working on it, and then render it when I’m done. To preview the document, run the following in your terminal (use the command palette in VS and then select “Terminal: Open a new terminal” or learn the shortcut keys):\nquarto preview template.qmd \nYou should see that a web browser opens up with the rendered document. As you make changes, they should appear in the browser automatically. You’ll see localhost:XXXX in your URL bar.\nTo render this document to PDF or DOCX, you have a few options. My favorite is to use the terminal again. For example, to convert to PDF:\nquarto render template.qmd --to pdf\nIf you run into issues, try the following two tips\n\nMake sure you’re typing these commands into the terminal and not into the Julia REPL\nIn the Julia REPL, type ] to enter package manager mode and then type build IJulia to rebuild your IJulia kernel (we won’t go into details)"
  },
  {
    "objectID": "labs/lab-02/index.html#getting-help",
    "href": "labs/lab-02/index.html#getting-help",
    "title": "Lab 2: Julia Quickstart",
    "section": "Getting help",
    "text": "Getting help\nIf you’re getting stuck, please:\n\nCome up and ask me questions if we’re in lab\nPost on Canvas discussions\nIf I can’t resolve your comment on Canvas, please email me to schedule a 1:1"
  },
  {
    "objectID": "labs/lab-02/index.html#looking-ahead",
    "href": "labs/lab-02/index.html#looking-ahead",
    "title": "Lab 2: Julia Quickstart",
    "section": "Looking ahead",
    "text": "Looking ahead\nIn the future, you’ll repeat these steps for every lab:\n\nclone the repository to your computer\nactivate the project environment\ninstantiate the packages\nmake your changes, saving and commiting regularly as you go\npush your changes to GitHub (you don’t have to wait until the end for this – you can push multiple times)"
  },
  {
    "objectID": "labs/lab-02/index.html#document-metadata",
    "href": "labs/lab-02/index.html#document-metadata",
    "title": "Lab 2: Julia Quickstart",
    "section": "Document metadata",
    "text": "Document metadata\nIf you open a Quarto file in your text editor (e.g., VS Code) or look at it on GitHub, you’ll see that the file starts with some metadata. The metadata is a set of key-value pairs that tell Quarto how to render the document. In Lab 01, you edited the author field to include your name."
  },
  {
    "objectID": "labs/lab-02/index.html#latex-math",
    "href": "labs/lab-02/index.html#latex-math",
    "title": "Lab 2: Julia Quickstart",
    "section": "LaTeX Math",
    "text": "LaTeX Math\nAs in standard Pandoc markdown, you can use LaTeX math in Quarto. For example, $\\alpha$ yields \\alpha. You can also use $$ to create a block equation:\n$$\nP(E) = \\{ n \\choose k \\} p ^k (2-p) ^ {n-k}\n$$\nrenders as\n\nP(E) = { n \\choose k } p ^k (2-p) ^ {n-k}\n\nFor more, see the “Typesetting Math” section of the resources page."
  },
  {
    "objectID": "labs/lab-02/index.html#source-code",
    "href": "labs/lab-02/index.html#source-code",
    "title": "Lab 2: Julia Quickstart",
    "section": "Source code",
    "text": "Source code\nSometimes we want to provide example code in our documents. This is code that is not meant to be run, but is just there to illustrate a point. We do that by wrapping the code in ```. For example:\n```\nf(x) = 1.25 * sin(2π * x / 1.5 + 0.5) + 0.25\nf(2.1)\n```\nyields\nf(x) = 1.25 * sin(2π * x / 1.5 + 0.5) + 0.25\nf(2.1)\nYou will typically want to specify the language of the code block, which will tell Quarto how to syntax highlight it. For example, see how the highlighting changes when we specify julia:\n```julia\nf(x) = 1.25 * sin(2π * x / 1.5 + 0.5) + 0.25\nf(2.1)\n```\nf(x) = 1.25 * sin(2π * x / 1.5 + 0.5) + 0.25\nf(2.1)"
  },
  {
    "objectID": "labs/lab-02/index.html#code-blocks",
    "href": "labs/lab-02/index.html#code-blocks",
    "title": "Lab 2: Julia Quickstart",
    "section": "Code blocks",
    "text": "Code blocks\nOften, we don’t just want to show code, but we want to run it and show the output.\n```{julia}\nf(x) = 1.25 * sin(2π * x / 1.5 + 0.5) + 0.25\nf(2.1)\n```\nwhich yields\n\nf(x) = 1.25 * sin(2π * x / 1.5 + 0.5) + 0.25\nf(2.1)\n\n0.4099583491000567\n\n\nYou can run these blocks in Julia by clicking the “Run Cell” button, or by pressing the keyboard shortcut (to see it, open the command palette and search for “Run Cell”). For more on Julia, see here."
  },
  {
    "objectID": "labs/lab-02/index.html#citations",
    "href": "labs/lab-02/index.html#citations",
    "title": "Lab 2: Julia Quickstart",
    "section": "Citations",
    "text": "Citations\nYou can add citations in Quarto. The easiest way is to export a bibliography from Zotero, and then add it to your Quarto document. You can use the Zotero Better BibTeX plugin to export a .bib file.\nSee here for instructions on using references with Quarto or see the website code for an example. I’ll provide a template for your final project."
  },
  {
    "objectID": "labs/lab-02/index.html#loading-packages",
    "href": "labs/lab-02/index.html#loading-packages",
    "title": "Lab 2: Julia Quickstart",
    "section": "Loading packages",
    "text": "Loading packages\nIn Julia we say using to import a package. By convention we’ll put these at the top of our script or notebook in alphabetical order. When you run this cell, you’ll see a bunch of activity in your REPL as Julia goes through the following steps:\n\nDownload a file from the internet that specifies which packages depend on which other packages\nSolve an optimization problem to identify which versions of which packages (including dependencies, and their dependencies, and so on) are compatible with each other\nDownload the packages and compile them (this may take a few minutes)\n\n\nusing CSV\nusing DataFrames\nusing DataFramesMeta\nusing Dates\nusing Plots\nusing StatsBase: mean\nusing StatsPlots\nusing Unitful"
  },
  {
    "objectID": "labs/lab-02/index.html#read-in-data",
    "href": "labs/lab-02/index.html#read-in-data",
    "title": "Lab 2: Julia Quickstart",
    "section": "Read in data",
    "text": "Read in data\nWe will use the CSV.jl package to read in our data.\n\n\n\n\n\n\nHover over the numbers on the right of this code for explanations.\n\n\n\n\n1fname = \"data/tidesandcurrents-8638610-1928-NAVD-GMT-metric.csv\"\n2df = CSV.read(fname, DataFrame)\n3first(df, 5)\n\n\n1\n\nWe define a variable called fname that stores the path to our data file. The data folder is in the same directory as this notebook.\n\n2\n\nWe use the CSV.read function to read in the data. The first argument is the filename, and the second argument tells Julia to convert the data to a DataFrame. We store it as a variable called df.\n\n3\n\nWe use the first function to show the first 5 rows of the DataFrame.\n\n\n\n\n5×5 DataFrame\n\n\n\nRow\nDate Time\nWater Level\nSigma\nI\nL\n\n\n\nString31\nFloat64\nFloat64\nInt64\nInt64\n\n\n\n\n1\n1928-01-01 00:00\n-0.547\n0.0\n0\n0\n\n\n2\n1928-01-01 01:00\n-0.699\n0.0\n0\n0\n\n\n3\n1928-01-01 02:00\n-0.73\n0.0\n0\n0\n\n\n4\n1928-01-01 03:00\n-0.669\n0.0\n0\n0\n\n\n5\n1928-01-01 04:00\n-0.516\n0.0\n0\n0\n\n\n\n\n\n\nThis data comes from the NOAA Tides and Currents website, specifically for a station at Sewells Point, VA for the year 1928. NAVD refers to the North American Vertical Datum, which is a reference point for measuring sea level, and GMT refers to Greenwich Mean Time, which is the time zone used in the data (rather than local time).\nWe can see that our DataFrame has five columns, the first of which is “Date Time”. However, the “Date Time” column is being parsed as a string. We want it to be a DateTime object from the Dates package. To do that, we need to tell Julia how the dates are formatted. We could then manually convert, but CSV.read has a kewyord argument that we can use\n\n1date_format = \"yyyy-mm-dd HH:MM\"\n2df = CSV.read(fname, DataFrame; dateformat=date_format)\nfirst(df, 3)\n\n\n1\n\nThis is a string that tells Julia how the dates are formatted. For example, 1928-01-01 00:00. See the documentation for more information.\n\n2\n\ndateformat is a keyword argument while date_format is a variable whose value is \"yyyy-mm-dd HH:MM\". We could equivalently write dateformat=\"yyyy-mm-dd HH:MM\".\n\n\n\n\n3×5 DataFrame\n\n\n\nRow\nDate Time\nWater Level\nSigma\nI\nL\n\n\n\nDateTime\nFloat64\nFloat64\nInt64\nInt64\n\n\n\n\n1\n1928-01-01T00:00:00\n-0.547\n0.0\n0\n0\n\n\n2\n1928-01-01T01:00:00\n-0.699\n0.0\n0\n0\n\n\n3\n1928-01-01T02:00:00\n-0.73\n0.0\n0\n0\n\n\n\n\n\n\nThe next column is “Water Level”, which is the height of the water above the reference point (NAVD) in meters. We can see that this is being parsed as a float, which is what we want 👍. However, you have to know that the data is in meters rather than inches or feet or something else. To explicitly add information about the units, we can use the Unitful package.\n\n1df[!, \" Water Level\"] .*= 1u\"m\"\nfirst(df, 3)\n\n\n1\n\nWe select the column with water levels using its name. The ! means “all rows”. Thus, df[!, \" Water Level\"] is a vector of all the water levels stored. *= means to multiply in place. For example, if x=2 then x *= 2 is equivalent to x = x * 2. .*= is a vector syntax, meaning do the multiplication to each element of the vector individually. 1u\"m\" is a Unitful object that represents 1 meter. We multiply the water levels by this to convert them to meters.\n\n\n\n\n3×5 DataFrame\n\n\n\nRow\nDate Time\nWater Level\nSigma\nI\nL\n\n\n\nDateTime\nQuantity…\nFloat64\nInt64\nInt64\n\n\n\n\n1\n1928-01-01T00:00:00\n-0.547 m\n0.0\n0\n0\n\n\n2\n1928-01-01T01:00:00\n-0.699 m\n0.0\n0\n0\n\n\n3\n1928-01-01T02:00:00\n-0.73 m\n0.0\n0\n0"
  },
  {
    "objectID": "labs/lab-02/index.html#subsetting-and-renaming",
    "href": "labs/lab-02/index.html#subsetting-and-renaming",
    "title": "Lab 2: Julia Quickstart",
    "section": "Subsetting and renaming",
    "text": "Subsetting and renaming\nWe want to only keep the first two (for more on the other three, see here). We can also rename the columns to make them easier to work with (spaces in variable names are annoying). To do this, we use the @rename function:\n\n1df = @rename(df, :datetime = $\"Date Time\", :lsl = $\" Water Level\");\n\n\n1\n\nThe $ is needed here because the right hand side is a string, not a Symbol.\n\n\n\n\nThen, we can use the @select function to select the columns we want. Notice how the first argument to select is the DataFrame and the subsequent arguments are column names. Notice also that our column names were strings (\"Date Time\"), but we can also use symbols (:datetime).\n\ndf = @select(df, :datetime, :lsl)\nfirst(df, 3)\n\n3×2 DataFrame\n\n\n\nRow\ndatetime\nlsl\n\n\n\nDateTime\nQuantity…\n\n\n\n\n1\n1928-01-01T00:00:00\n-0.547 m\n\n\n2\n1928-01-01T01:00:00\n-0.699 m\n\n\n3\n1928-01-01T02:00:00\n-0.73 m\n\n\n\n\n\n\nFor more on what DataFramesMeta can do, see this Tweet."
  },
  {
    "objectID": "labs/lab-02/index.html#time-series-plot",
    "href": "labs/lab-02/index.html#time-series-plot",
    "title": "Lab 2: Julia Quickstart",
    "section": "Time series plot",
    "text": "Time series plot\nNow we’re ready to make some plots of our data. Let’s start with a simple time series plot of the water levels. Our data is collected hourly, so we have a lot of data points! Still, we can plot them all.\n\nplot(\n    df.datetime,\n    df.lsl;\n    title=\"Hourly Water levels at Sewells Point, VA\",\n    ylabel=\"Water level\",\n    label=false,\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFocusing on the entire time series means we can’t dig into the details. Let’s zoom in on a single month (October 1928) using the @subset function.\n\n1t_start = Dates.DateTime(1928, 10, 1, 0)\nt_end = Dates.DateTime(1928, 10, 31, 23)\n2df_month = @subset(df, t_start .&lt;= :datetime .&lt;= t_end)\nfirst(df_month, 3)\n\n\n1\n\nThis creates a DateTime object for the start of October 1928 at 0 hours. Defining it clearly here aids readability.\n\n2\n\nThis selects all the rows where the :datetime column is between t_start and t_end. The . syntax is called dot broadcasting and is a way to apply a function to each element of a vector.\n\n\n\n\n3×2 DataFrame\n\n\n\nRow\ndatetime\nlsl\n\n\n\nDateTime\nQuantity…\n\n\n\n\n1\n1928-10-01T00:00:00\n0.215 m\n\n\n2\n1928-10-01T01:00:00\n0.429 m\n\n\n3\n1928-10-01T02:00:00\n0.581 m\n\n\n\n\n\n\nNow we can plot it as above:\n\nplot(\n    df_month.datetime,\n    df_month.lsl;\n    title=\"Water levels at Sewells Point, VA\",\n    ylabel=\"Water level\",\n    label=false,\n)"
  },
  {
    "objectID": "labs/lab-02/index.html#climatology",
    "href": "labs/lab-02/index.html#climatology",
    "title": "Lab 2: Julia Quickstart",
    "section": "Climatology",
    "text": "Climatology\nAn essential idea in working with tabular data (and other data formats) is “split-apply-combine”. Essentially: split the data into groups, apply some function to each group, and then combine the results.\nWe can use this workflow to answer an interesting question: what is the average water level for each month?2 Of course, we’re only looking at one year of data here – we should ideally look at a long record!\n\n1df[!, :month] = Dates.month.(df.datetime)\n2dropmissing!(df, :lsl)\n3df_bymonth = groupby(df, :month)\n4df_climatology = combine(df_bymonth, :lsl =&gt; mean =&gt; :lsl_avg);\n\n\n1\n\nThis creates a new column called :month that is the month of each observation.\n\n2\n\nThis will discard any rows in df that have a missing value of :lsl. This is necessary because the mean function will return missing if any of the values are missing.\n\n3\n\nThis creates a GroupedDataFrame object that contains all the data grouped by month.\n\n4\n\nThis takes the grouped data and calculates the mean of the :lsl column for each month. The general syntax is combine(grouped_df, :column =&gt; function).\n\n\n\n\nWe can now plot the climatology.\n\nplot(\n1    df_climatology.month,\n    df_climatology.lsl_avg;\n2    xticks=1:12,\n    xlabel=\"Month\",\n    ylabel=\"Average Water level\",\n3    linewidth=3,\n    label=false,\n)\n\n\n1\n\nWe can use df.colname instead of df[!, :colname]. The latter is more robust but the former is easier to type.\n\n2\n\nSetting xticks will set the x-axis ticks to the values in the vector. We can use this to make sure the x-axis ticks are labeled with the months.\n\n3\n\nWe can set the line width to make the plot easier to read."
  },
  {
    "objectID": "labs/lab-02/index.html#footnotes",
    "href": "labs/lab-02/index.html#footnotes",
    "title": "Lab 2: Julia Quickstart",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nJulia precompiles packages when they are installed, and (to a lesser extent) when they are first used. The first time you use a package it may take a moment to load. This is normal, nothing to worry about, and rapidly improving.↩︎\nTo do a better job, we should separate out the long-term trend from the seasonal cycle. This is called de-trending and is a common technique in climate science. We can worry more about this later.↩︎"
  },
  {
    "objectID": "labs/lab-04/template.html",
    "href": "labs/lab-04/template.html",
    "title": "Lab 4: House Elevation NPV Analysis",
    "section": "",
    "text": "using CSV\nusing DataFrames\nusing DataFramesMeta\nusing Distributions\nusing Interpolations\nusing Plots\nusing StatsPlots\nusing Unitful\n\nPlots.default(; margin=6Plots.mm)"
  },
  {
    "objectID": "labs/lab-03/template.html",
    "href": "labs/lab-03/template.html",
    "title": "Lab 3: Depth-Damage Models",
    "section": "",
    "text": "using CSV\nusing DataFrames\nusing DataFramesMeta\nusing Distributions\nusing Interpolations\nusing Plots\nusing StatsPlots\nusing Unitful\n\nPlots.default(; margin=6Plots.mm)\n\n\nSite information\n\n\nDepth-Damage\n\n\nExpected annual damages\n\n\nDiscussion"
  },
  {
    "objectID": "labs/lab-08/index.html",
    "href": "labs/lab-08/index.html",
    "title": "Lab 8: Parking Garage Case Study",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-08/index.html#overview",
    "href": "labs/lab-08/index.html#overview",
    "title": "Lab 8: Parking Garage Case Study",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-01/index.html",
    "href": "labs/lab-01/index.html",
    "title": "Lab 1: Software Installation",
    "section": "",
    "text": "Labs are in-class exercises intended to get practice with coding or analysis workflows.\n\nInstructions available on website\nDownload ahead of time by using link from Canvas\nYou will have your own repository (more in a minute)\nTry to finish in class, but due in 1 week"
  },
  {
    "objectID": "labs/lab-01/index.html#labs",
    "href": "labs/lab-01/index.html#labs",
    "title": "Lab 1: Software Installation",
    "section": "",
    "text": "Labs are in-class exercises intended to get practice with coding or analysis workflows.\n\nInstructions available on website\nDownload ahead of time by using link from Canvas\nYou will have your own repository (more in a minute)\nTry to finish in class, but due in 1 week"
  },
  {
    "objectID": "labs/lab-01/index.html#toolkit-overview",
    "href": "labs/lab-01/index.html#toolkit-overview",
    "title": "Lab 1: Software Installation",
    "section": "Toolkit: overview",
    "text": "Toolkit: overview\nGetting set up for this course requires the following steps. If you are an experienced programmer, you are free to follow your own workflow to set up these tools. You will absolutely need Quarto, GitHub, and Julia. If you are not an experienced programmer, the following steps are not the only way to get these tools set up, but they are a very good way.\nIf you install course tools using steps other than the ones provided on this page, be aware that your instructors may be able to provide you with only limited support.\n\nJulia\nWe’re using the Julia programming language in this course. Julia is a fast, modern, open-source programming language designed for numerical and scientific computing.\nWe’re using it for a few key reasons. First, the syntax is human-readable and closely parallels math notation, which reduces the cognitive burden of translating between conceptual and computational models. Second, it’s fast, which means that Julia solves the “two language problem”: you don’t need to learn C or Fortran to dig under the hood and write fast code. Other great features include that it’s open-source, which makes it reproducible and shareable, and it has a fantastic package manager.\nThere are some great resources out there about why Julia is great. See posts by Julia Data Science or the Julia Creators (with followup).\n\n\nGitHub\ngit is a software tool for version control that keeps track of changes to files over time. GitHub is a website that hosts git repositories and provides a web interface for interacting with them.\nTo use GitHub, you’ll need a GitHub account. Code on GitHub is stored in repositories. A simple workflow is to clone a repository to your computer, make changes, commit them, then push your changes to GitHub.\nWe will also use GitHub classroom, which allows instructors to share templates and view your code.\n\n\nQuarto\nQuarto is a tool that allows you to combine text and code and create many types of output. For example, this website is made with Quarto! You will use Quarto to create reports for labs. This lets you keep everything in one place – no more running code, saving a figure to Downloads, copying into Word, then trying to remember where to paste the figure when you update the code.\n\n\nVS Code\nVS Code is a text editor. If you are an advanced user of another text editor, you can use that instead. However, VS Code is very nearly an officially supported IDE for Julia."
  },
  {
    "objectID": "labs/lab-01/index.html#installing-software",
    "href": "labs/lab-01/index.html#installing-software",
    "title": "Lab 1: Software Installation",
    "section": "Installing software",
    "text": "Installing software\n\nInstall Julia\nThe best way to install Julia is through the juliaup tool, which will let you easily manage versions in the future and works seamlessly with VS Code. The instructions can be found at the JuliaUp GitHub repository, but we will summarize them here.\nIf your computer uses Windows, you can install Juliaup from the Windows Store.\nIf you have a Mac (or are using Linux), open a terminal (such as the Terminal app) and enter:\ncurl -fsSL https://install.julialang.org | sh\nOnce you install Juliaup, install Julia version 1.10 by opening a terminal (in MacOS or Linux) or the command line (in Windows) and entering:\njuliaup add 1.10\njuliaup default 1.10\nThis will install Julia 1.10 and make it the default version, which should maximize package compatibility throughout this course. Going forward, if you want to add new versions or change the default, you can follow the Juliaup instructions.\n\n\nInstall VS Code\nVS Code is as close to an officially supported editor for Julia as you can get. We will follow this guide for setting up VS Code with Julia.\n\nYou can skip this section if you are an experienced programmer and already have a preferred IDE. Your IDE will likely have instructions for Julia and Quarto setup.\n\nYou can download VS Code here; open the downloaded file to install. Make sure to select the correct version for your operating system. If you have a newish Apple mac (with M1, M2, or M3 chip), make sure to check whether you have an Intel or Apple chip before choosing which version to download. You can also use homebrew or your preferred package manager to install VS Code.\n\nVS Code Julia Extension\nLike many IDEs, VS Code is a modular system that can be extended with plugins. We will install the Julia extension, which will allow us to run Julia code and interact with the Julia REPL from within VS Code (we’ll add the Quarto extension later).\n\nOpen VS Code.\nSelect View and click Extensions to open the Extension View.\nSearch for julia in the search box. Click the green install button.\nRestart VS Code once the installation is complete. It should automatically find your Julia installation; reach out if not.\n\nThe Julia VS Code extension offers you some nice features. You can start a REPL (an interactive Julia coding environment) by opening the “Command Palette” (View -&gt; Command Palette, or CTRL/CMD+SHIFT+P) and typing “REPL” to bring up “Julia: Start REPL”. You can also create .jl and .qmd files to write Julia code and execute line by line.\n\n\n\nGitHub\nSee GitHub official tutorials for more helpful resources and tutorials.\n\nCreate GitHub Account\nIf you already have a GitHub account, you can use that for this course and do not need to create a new account. Otherwise, create an account. It doesn’t have to be linked to your Rice email or your NetID.\nFor labs and projects, you should use the GitHub Classroom link posted on Canvas to “accept” the assignment, which will give you your own GitHub repository for that assignment. The first time you click one of these links, you will need to link your place on the course roster with your GitHub account.\n\n\nGitHub Desktop (Optional)\nYou can do everything that you will need to do for this course with GitHub directly through VS Code. The GitHub desktop app is also great, or alternatively you may work directly through the terminal if you have prior experience.\n\n\n\nGitHub Copilot (Optional)\nGitHub Copilot is an AI-powered tool that helps you write code. You can install it following instructions here As described in the quickstart guide, Copilot is free for students. Be sure to review the policy on AI language models in the syllabus!\n\nInstall Git\ngit is a version control software that powers GitHub under the hood (git is the version control software, GitHub is an online platform). Based on past experience with the course, you probably already have git installed! If you’re not sure if it’s installed, see instructions here.\n\n\n\nInstall Quarto\nQuarto combines the best of Jupyter notebooks and R Markdown to create a document format that is ideal for conducting and communicating data science. We will use Quarto to create and share our work in this course; this website is also built using Quarto.||\nFollow the documentation to install Quarto. Be sure to ensure that you have the right version for your operating system.\n\nInstall the Quarto Extension for VS Code\nUnder “Step 2”, click on the VS Code icon.\n\n\nInstall Jupyter\nUnder the hood, Quarto uses Jupyter to run code. You don’t need to know how Jupyter works or worry about it, because it runs under the hood, but we will need to install it. Jupyter is a Python package.\nIf you don’t have Python installed (if you’re not sure, you should install Miniconda below), you’ll need to install it. The best way, by far, is to install Miniconda (see Conda documentation).\nOnce you have Python installed, you can open your Terminal (open VS Code then open the terminal), then run\npython3 -m pip install jupyter\n\n\n\n\n\n\nBased on past experience, getting Jupyter installed and Quarto to find your Jupyter installation is the most common source of problems, especially on Windows machines. Please start this early so you have a full week to get help if you need it."
  },
  {
    "objectID": "labs/lab-01/index.html#lab-instructions",
    "href": "labs/lab-01/index.html#lab-instructions",
    "title": "Lab 1: Software Installation",
    "section": "Lab Instructions",
    "text": "Lab Instructions\nOnce you have everything set up, your lab for the week will be to complete the following steps. These will ensure that your installation is working smoothly!\n\nFollow the link to lab 1 assignment from Canvas (it should start with classroom.github.com). You will get a message saying ” Your assignment repository has been created: …“. Click on the link to go to your repository.\nclone the repository for lab 01 (use the Github Classroom link from Canvas) to your computer. You can use VS Code functionality, GitHub Desktop, or your terminal.\nOpen the directory containing the repository in VS Code doing one of the following:\n\nFrom GitHub desktop: Repository &gt; Open in Visual Studio Code\nIn VS Code: File &gt; Open Folder...\n\nOpen the index.qmd file in VS Code and replace the author: CEVE 421/521 line with your name and netID\nOpen the JULIA Repl\n\nOpen the command palette (Ctrl+Shift+P on Windows/Linux, Cmd+Shift+P on Mac)\nStart typing “Julia: Start REPL”. It will auto-complete; select the command as it appears.\n\nSet up your project environment.\n\nIn the Julia REPL, type ] to enter the package manager. It should now show something like (lab-01) pkg&gt;.\nType instantiate and run it (Enter). This will install all the packages needed for this lab.\nType the backspace key to exit the package manager.\n\nEdit the index.qmd file to add your name and netID\nRender the document\n\nOpen the index.qmd file\nOpen the command palette and run “Quarto: Preview”. After some activity, a preview of the rendered document should open in VS Code. If you see something like Browse at http://localhost:4200/index.html you can open that link in your web browser to see the rendered document.\nRender to PDF or Microsoft Word following the directions below.\n\nIf you’re still having trouble:\n\nTry running build IJulia in the Julia REPL’s Pkg mode (type ])\nCome to office hours\nPost on the Canvas discussion for Lab 1\n\ncommit and push your changes to GitHub\nSubmit your rendered .docx or .pdf file to Canvas\n\n\nRunning Code\nWe can use Quarto to run Julia code in-line\n\nprintln(\"I'm using Julia!\")\n\nI'm using Julia!\n\n\nWe can also load packages\n\nusing CairoMakie\nusing LaTeXStrings\n\nand use them to make plots\n\nf = Figure()\nax = Axis(f[1, 1]; title=L\"$y = \\sin(x)$\", xlabel=L\"$x$\", ylabel=L\"$y$\")\nx = range(0, 10; length=100)\ny = sin.(x)\nlines!(ax, x, y)\nf\n\n\n\n\n\n\n\n\n\n\nRendering the Document\nA Quarto document is a plain text file that uses a simple code language to embed text, math, code, and the code’s output. You can run the document line by line, or you can render to a variety of formats. This is helpful for sharing with others, or for creating a final document for yourself.\nWe will check our ability to\n\nPreview the document in HTML (a web-native format)\nRender the document to PDF or Microsoft Word (a portable, shareable, and printable format)\n\n\nHTML\nFirst, verify that you can preview the document in HTML:\n\nOpen the command palette (Cmd+Shift+P on macOS, Ctrl+Shift+P on Windows/Linux)\nType “Quarto: Preview”\n\n\n\nPDF\nYou can use Quarto to generate PDF documents. Follow the instructions on Quarto’s website to install the necessary software.\n\nTo instruct Quarto to render to PDF, you need to edit the document metadata. Specifically, uncomment the lines in the document metadata corresponding to the PDF format.\nOpen the command palette (Cmd+Shift+P on macOS, Ctrl+Shift+P on Windows/Linux)\nType “Quarto: Render”\n\n\n\nWord\nYou can also render the document to Microsoft Word. See the Quarto documentation.\n\nTo instruct Quarto to render to Word, you need to edit the document metadata. Specifically, uncomment the lines in the document metadata corresponding to the Word format.\nOpen the command palette (Cmd+Shift+P on macOS, Ctrl+Shift+P on Windows/Linux)\nType “Quarto: Render”"
  },
  {
    "objectID": "labs/lab-09/index.html",
    "href": "labs/lab-09/index.html",
    "title": "Lab 9: The Lake Problem",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-09/index.html#overview",
    "href": "labs/lab-09/index.html#overview",
    "title": "Lab 9: The Lake Problem",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-07/index.html",
    "href": "labs/lab-07/index.html",
    "title": "Lab 7: Multiobjective Optimization",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-07/index.html#overview",
    "href": "labs/lab-07/index.html#overview",
    "title": "Lab 7: Multiobjective Optimization",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-06/index.html",
    "href": "labs/lab-06/index.html",
    "title": "Lab 6: Policy Search",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-06/index.html#overview",
    "href": "labs/lab-06/index.html#overview",
    "title": "Lab 6: Policy Search",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-03/index.html",
    "href": "labs/lab-03/index.html",
    "title": "Lab 3: Depth-Damage Models",
    "section": "",
    "text": "Today, we’re going to be working with depth-damage functions. This will give us practice:\n\nworking with and manipulating tabular data\nwriting functions\n\nIn addition, the depth-damage function you choose / build will be a building block for your final project.\n\n\nAs before:\n\nClone the repository for this lab to your computer and open it in VS Code.\nIn the Julia REPL, activate and then instantiate the project environment.\nCheck that you can preview the project by running quarto preview template.qmd in the terminal (not Julia REPL). If that doesn’t work, open the Julia REPL, enter package mode with ], and run build IJulia.\nIf that doesn’t work, ask for help! The way VS Code looks for Python on your computer can be weird and counterintuitive.\n\n\n\n\nAs usual, we load all required packages at the top of the notebook, in one place.\n\nusing CSV\nusing DataFrames\nusing DataFramesMeta\nusing Distributions\nusing Interpolations\nusing Plots\nusing StatsPlots\nusing Unitful\n\n1Plots.default(; margin=6Plots.mm)\n\n\n1\n\nThis updates the default margin in our plots so that axis labels don’t get cut off."
  },
  {
    "objectID": "labs/lab-03/index.html#setup",
    "href": "labs/lab-03/index.html#setup",
    "title": "Lab 3: Depth-Damage Models",
    "section": "",
    "text": "As before:\n\nClone the repository for this lab to your computer and open it in VS Code.\nIn the Julia REPL, activate and then instantiate the project environment.\nCheck that you can preview the project by running quarto preview template.qmd in the terminal (not Julia REPL). If that doesn’t work, open the Julia REPL, enter package mode with ], and run build IJulia.\nIf that doesn’t work, ask for help! The way VS Code looks for Python on your computer can be weird and counterintuitive."
  },
  {
    "objectID": "labs/lab-03/index.html#load-packages",
    "href": "labs/lab-03/index.html#load-packages",
    "title": "Lab 3: Depth-Damage Models",
    "section": "",
    "text": "As usual, we load all required packages at the top of the notebook, in one place.\n\nusing CSV\nusing DataFrames\nusing DataFramesMeta\nusing Distributions\nusing Interpolations\nusing Plots\nusing StatsPlots\nusing Unitful\n\n1Plots.default(; margin=6Plots.mm)\n\n\n1\n\nThis updates the default margin in our plots so that axis labels don’t get cut off."
  },
  {
    "objectID": "labs/lab-03/index.html#parsing",
    "href": "labs/lab-03/index.html#parsing",
    "title": "Lab 3: Depth-Damage Models",
    "section": "Parsing",
    "text": "Parsing\nWe’d like to be able to use the depth-damage functions in this file. However, the depths are stored in a somewhat annoying format (e.g., “ft04m” means -4 feet). To make life simple, I’ve created some functionality in the depthdamage.jl file that you can use. We can load it as follows:\n\ninclude(\"depthdamage.jl\")\n\nDepthDamageData\n\n\nThe main thing that we’ll use is called DepthDamageData. This is a data structure or type that stores the depth-damage data, as well as any relevant metadata. If you’ve created a class in a language like C++ or Python, it’s the same idea. I’ve also defined a constructor that takes in the row of a DataFrame and creates a DepthDamageData object, to make life easy.\nI’ll show you how to do this for an illustrative depth-damage function from the New Orleans USACE.\n\ndemo_row = @rsubset(\n    haz_fl_dept, :Description == \"one story, Contents, fresh water, short duration\"\n)[\n    1, :,\n]\ndd = DepthDamageData(demo_row)\n\nDepthDamageData(Quantity{Float64, 𝐋, Unitful.FreeUnits{(ft,), 𝐋, nothing}}[-4.0 ft, -3.0 ft, -2.0 ft, -1.0 ft, 0.0 ft, 1.0 ft, 2.0 ft, 3.0 ft, 4.0 ft, 5.0 ft  …  15.0 ft, 16.0 ft, 17.0 ft, 18.0 ft, 19.0 ft, 20.0 ft, 21.0 ft, 22.0 ft, 23.0 ft, 24.0 ft], [0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 63.0, 82.0, 85.0, 91.0  …  91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0], String7(\"RES1\"), \"57\", String31(\"USACE - New Orleans\"), \"one story, Contents, fresh water, short duration\", \"missing\")\n\n\nThis prints out a bunch of data. We can see that it has the following fields, which should broadly match with our DataFrame:\n\nfieldnames(typeof(dd))\n\n(:depths, :damages, :occupancy, :dmg_fn_id, :source, :description, :comment)"
  },
  {
    "objectID": "labs/lab-03/index.html#plotting",
    "href": "labs/lab-03/index.html#plotting",
    "title": "Lab 3: Depth-Damage Models",
    "section": "Plotting",
    "text": "Plotting\nNow that we’ve created a DepthDamageData object, we can plot it. When we plot things with units, the Unitful package (as long as we are using it) knows how to handle them.\n\nscatter(\n    dd.depths,\n    dd.damages;\n    xlabel=\"Flood Depth at House\",\n    ylabel=\"Damage (%)\",\n    label=\"$(dd.description) ($(dd.source))\",\n    legend=:bottomright,\n    size=(700, 500),\n)"
  },
  {
    "objectID": "labs/lab-03/index.html#interpolating",
    "href": "labs/lab-03/index.html#interpolating",
    "title": "Lab 3: Depth-Damage Models",
    "section": "Interpolating",
    "text": "Interpolating\nThis is great. However, what if we want to estimate damage between the points? We need a way to interpolate. We can do this using the Interpolations package!\n\n1itp = let\n2    depth_ft = ustrip.(u\"ft\", dd.depths)\n    damage_frac = dd.damages\n    Interpolations.LinearInterpolation(\n        depth_ft,\n        damage_frac;\n3        extrapolation_bc=Interpolations.Flat(),\n    )\nend\n\n\n1\n\nI really like these let...end blocks and use them quite a bit. The main thing to know is that all the variables defined inside the let block are only available inside the let block. Once we get to the end of the block, they vanish! This keeps us from defining tons of variables that get in each others’ way.\n\n2\n\nThe Interpolations package doesn’t take units on its input, so we convert the input (which can be of any length unit) to feet before passing it in. If our depths are in meters or millimeters, it won’t be a problem – the ustrip function will convert to feet and then turn them into scalars.\n\n3\n\nInterpolations requires us to specify how to extrapolate. We choose Flat(), meaning that anything below the lowest value in the table will be assumed to have the same damage as the lowest value in the table and anything above the highest value in the table will be assumed to have the same damage as the highest value in the table.\n\n\n\n\nNow we can use this interpolation function to estimate damage at any depth.\n\nlet\n1    dmg_fn(x) = itp(ustrip.(u\"ft\", x))\n2    dmg_fn.([3.1u\"ft\", 2.2u\"m\", 91.4u\"inch\"])\nend\n\n\n1\n\nConvert the input to feet\n\n2\n\nEstimate damage at 3.1 feet, 2.2 meters, and 91.4 inches\n\n\n\n\n3-element Vector{Float64}:\n 82.30000000000001\n 91.0\n 91.0"
  },
  {
    "objectID": "labs/lab-03/index.html#packaging",
    "href": "labs/lab-03/index.html#packaging",
    "title": "Lab 3: Depth-Damage Models",
    "section": "Packaging",
    "text": "Packaging\nTo make life simple, we can define a function that takes in some depths and some damages and returns a function that can be used to estimate damage at any depth.\n\nfunction get_depth_damage_function(\n    depth_train::Vector{&lt;:T}, dmg_train::Vector{&lt;:AbstractFloat}\n) where {T&lt;:Unitful.Length}\n\n    # interpolate\n    depth_ft = ustrip.(u\"ft\", depth_train)\n    interp_fn = Interpolations.LinearInterpolation(\n1        depth_ft,\n        dmg_train;\n2        extrapolation_bc=Interpolations.Flat(),\n    )\n\n    damage_fn = function (depth::T2) where {T2&lt;:Unitful.Length}\n3        return interp_fn(ustrip.(u\"ft\", depth))\n    end\n4    return damage_fn\nend\n\n\n1\n\nThe Interpolations package doesn’t take units on its input, so we convert the input (which can be of any length) to feet before passing it in. If our depths are in meters or millimeters, it won’t be a problem – the ustrip function will convert to feet and then turn them into scalars.\n\n2\n\nInterpolations requires us to specify how to extrapolate. We choose Flat(), meaning that anything below the lowest value in the table will be assumed to have the same damage as the lowest value in the table and anything above the highest value in the table will be assumed to have the same damage as the highest value in the table.\n\n3\n\nThis is a bit confusing. We are defining a function, inside of a function.\n\n4\n\nWe return the function that we just defined. So when we call this function, we get a function – we in turn need to call that function on something else.\n\n\n\n\nget_depth_damage_function (generic function with 1 method)\n\n\n\ndamage_fn = get_depth_damage_function(dd.depths, dd.damages)\n\n#16 (generic function with 1 method)\n\n\nNow damage_fn is a function. It takes in a depth, with some type of length unit defined using Unitful, and returns the damage in percent. We can use this to plot a depth-damage curve:\n\np = let\n1    depths = uconvert.(u\"ft\", (-7.0u\"ft\"):(1.0u\"inch\"):(30.0u\"ft\"))\n2    damages = damage_fn.(depths)\n    scatter(\n        depths,\n        damages;\n        xlabel=\"Flood Depth\",\n        ylabel=\"Damage (%)\",\n        label=\"$(dd.description) ($(dd.source))\",\n        legend=:bottomright,\n        size=(800, 400),\n        linewidth=2,\n    )\nend\np\n\n\n1\n\nWe create a vector of depths from -7 feet to 30 feet, in 1 inch increments. We use uconvert to convert the units to feet (by default, Unitful converts to meters when we add together length units).\n\n2\n\nOur damage_fn is defined to take in a single scalar. To make predictions about a Vector of depths, we use . to broadcast the function over the vector.\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOf course, if we use plot instead of scatter, then we get a line plot which is automatically smooth."
  },
  {
    "objectID": "labs/lab-04/index.html",
    "href": "labs/lab-04/index.html",
    "title": "Lab 4: House Elevation Case Study",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-04/index.html#overview",
    "href": "labs/lab-04/index.html#overview",
    "title": "Lab 4: House Elevation Case Study",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-05/index.html",
    "href": "labs/lab-05/index.html",
    "title": "Lab 5: Sea-Level Rise",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-05/index.html#overview",
    "href": "labs/lab-05/index.html#overview",
    "title": "Lab 5: Sea-Level Rise",
    "section": "",
    "text": "This is a placeholder."
  },
  {
    "objectID": "labs/lab-02/template.html",
    "href": "labs/lab-02/template.html",
    "title": "Lab 2: Julia Quickstart",
    "section": "",
    "text": "We start by loading the packages we will use in this lab\n\nusing CSV\nusing DataFrames\nusing DataFramesMeta\nusing Dates\nusing Plots\nusing StatsBase: mean\nusing StatsPlots\nusing Unitful"
  },
  {
    "objectID": "labs/lab-02/template.html#first-steps",
    "href": "labs/lab-02/template.html#first-steps",
    "title": "Lab 2: Julia Quickstart",
    "section": "",
    "text": "We start by loading the packages we will use in this lab\n\nusing CSV\nusing DataFrames\nusing DataFramesMeta\nusing Dates\nusing Plots\nusing StatsBase: mean\nusing StatsPlots\nusing Unitful"
  },
  {
    "objectID": "labs/lab-02/template.html#defining-a-function",
    "href": "labs/lab-02/template.html#defining-a-function",
    "title": "Lab 2: Julia Quickstart",
    "section": "Defining a function",
    "text": "Defining a function\nIn index.qmd, we read in a CSV file from scratch. However, we’d like to repeat this process for each year of data, and to do it in a consistent way so that we can read in the data for all available years into a single file. To do this, we’ll write a function that we can use to read in the data for any year. Specifically, our function will take in the year as an argument, and return a DataFrame with the data for that year.\nBefore we do that, let’s define a function that will return the filename for a given year. It’s often valuable to stack several functions together.\n\nget_fname(year::Int) = \"data/tidesandcurrents-8638610-$(year)-NAVD-GMT-metric.csv\"\n\nNow we’re ready to define our function:\n\nfunction read_tides(year::Int)\n    \n    # define the CSV file corresponding to our year of choice\n    fname = get_fname(year)\n\n    # a constant, don't change this\n    date_format = \"yyyy-mm-dd HH:MM\"\n    \n    # &lt;YOUR CODE GOES HERE&gt;\n    # 1. read in the CSV file and save as a dataframe\n    # 2. convert the \"Date Time\" column to a DateTime object\n    # 3. convert the \" Water Level\" column to meters\n    # 4. rename the columns to \"datetime\" and \"lsl\"\n    # 5. select the \"datetime\" and \"lsl\" columns\n    # 6. return the dataframe\nend\n\n# print out the first 10 rows of the 1928 data\nfirst(read_tides(1928), 10) \n\n\n\n\n\n\nInstructions\n\n\n\nFill out this function. Your function should implement the six steps indicated in the instructions. Use the example code from index.qmd to help you. When it’s done, convert it to a live code block by replacing ```julia``` with ```{julia}```. When you run this code, it should print out the first 10 rows of the 1928 data. Make sure they look right!"
  },
  {
    "objectID": "labs/lab-02/template.html#building-the-dataset",
    "href": "labs/lab-02/template.html#building-the-dataset",
    "title": "Lab 2: Julia Quickstart",
    "section": "Building the dataset",
    "text": "Building the dataset\nNow that we have the ability to read in the data corresponding to any year, we can read them all in and combine into a single DataFrame. First, let’s read in all the data.\n\n\n\n\n\n\nInstructions\n\n\n\n\nHint: to vectorize a function means to apply it to each element of a vector. For example, f.(x) will apply the function f to each element of the vector x. This is a very common operation in Julia!\nUpdate the code blocks below, then replace ```julia``` with ```{julia}```.\n\n\n\nyears = 1928:2021 # all the years of data\nannual_data = # call the read_tides function on each year (see hint above!)\ntypeof(annual_data) # should be a vector of DataFrames\nNext, we’ll use the vcat function to combine all the data into a single DataFrame.\ndf = vcat(annual_data...)\nfirst(df, 5)\nAnd we can look at the last 5 rows\nlast(df, 5)\nFinally, we’ll make sure we drop any missing data.\ndropmissing!(df) # drop any missing data"
  },
  {
    "objectID": "labs/lab-02/template.html#plots",
    "href": "labs/lab-02/template.html#plots",
    "title": "Lab 2: Julia Quickstart",
    "section": "Plots",
    "text": "Plots\n\nPlot the hourly water levels for March 2020, using subsetting and plotting techniques from the instructions\nIn the instructions, we plotted the average monthly water level from each month using groupby. Repeat this analysis, using the full dataset (all years).\nNow repeat the analysis, but group by day of the year. What do you notice? (Hint: use Dates.dayofyear to get the day of the year from a DateTime object)"
  },
  {
    "objectID": "readings/week-09-reading.html",
    "href": "readings/week-09-reading.html",
    "title": "Readings for Week 9",
    "section": "",
    "text": "Discussion questions will be posted here.\n\n\n\nAssigned reading will be drawn from:\n\nHerman et al. (2020)\nQuinn et al. (2017)\nFletcher et al. (2019)\nSutton & Barto (2018)\n\n\n\n\n\nReferences\n\nFletcher, S., Lickley, M., & Strzepek, K. (2019). Learning about climate change uncertainty enables flexible water infrastructure planning. Nature Communications, 10(1), 1782. https://doi.org/10.1038/s41467-019-09677-x\n\n\nHerman, J. D., Quinn, J. D., Steinschneider, S., Giuliani, M., & Fletcher, S. (2020). Climate adaptation as a control problem: Review and perspectives on dynamic water resources planning under uncertainty. Water Resources Research, e24389. https://doi.org/10.1029/2019wr025502\n\n\nQuinn, J. D., Reed, P. M., & Keller, K. (2017). Direct policy search for robust multi-objective management of deeply uncertain socio-ecological tipping points. Environmental Modelling & Software, 92, 125–141. https://doi.org/10.1016/j.envsoft.2017.02.017\n\n\nSutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An Introduction (Second Edition). Cambridge, Massachusetts and London, England: MIT Press."
  },
  {
    "objectID": "readings/week-13-reading.html",
    "href": "readings/week-13-reading.html",
    "title": "Readings for Week 13",
    "section": "",
    "text": "Discussion questions will be posted here.\n\n\n\nAssigned reading will be drawn from:\n\nThomson et al. (2023)\nCondon (2021)\n\n\n\n\n\nReferences\n\nCondon, M. (2021). Market myopia’s climate bubble. https://doi.org/10.2139/ssrn.3782675\n\n\nThomson, H., Zeff, H. B., Kleiman, R., Sebastian, A., & Characklis, G. W. (2023). Systemic Financial Risk Arising From Residential Flood Losses. Earth’s Future, 11(4), e2022EF003206. https://doi.org/10.1029/2022EF003206"
  },
  {
    "objectID": "readings/week-03-reading.html",
    "href": "readings/week-03-reading.html",
    "title": "Readings for Week 3",
    "section": "",
    "text": "Please read Wing et al. (2020) for Wednesday’s class. As you read, please post any clarifying questions you have to Canvas.\nThis paper analyzes insurance claims data to evaluate and explore “depth-damage” curves. Please consider the following questions as you read:\n\nWhat is the difference between a probabilistic and deterministic depth-damage curve? What are practical advantages of a probabilistic depth-damage curve?\nIf you were predicting flood damages for a structure, what information besides flood depth might be useful?\nWhat might explain the regional patterns of depth-damage curves in the paper?\nWhat are some problems with using insurance claims data to develop or validate depth-damage curves?\n\nPlease also prepare a discussion question for class based on this paper.\n\n\n\n\nReferences\n\nWing, O. E. J., Pinter, N., Bates, P. D., & Kousky, C. (2020). New insights into US flood vulnerability revealed from flood insurance big data. Nature Communications, 11(1, 1), 1444. https://doi.org/10.1038/s41467-020-15264-2"
  },
  {
    "objectID": "readings/week-01-reading.html",
    "href": "readings/week-01-reading.html",
    "title": "Week 1 readings",
    "section": "",
    "text": "Please read the following news articles:\n\nFrank (2022)\nSommer (2022)\n\nYou are encouraged, though not required, to use Zotero to store your readings. You can save news articles using the browser extension for your browser of choice. If you save the news article as a PDF (go to “print” and then choose “save as PDF”) you can link the PDF to your library and your annotations will be saved.\nThere are other great tools, including Randrop.io and hypothes.is. Figure out what works for you!\n\n\n\n\nReferences\n\nFrank, T. (2022, August 22). Bold New Jersey Shore Flood Rules Could Be Blueprint for Entire U.S. Coast. Scientific American. Retrieved from https://www.scientificamerican.com/article/bold-new-jersey-shore-flood-rules-could-be-blueprint-for-entire-u-s-coast/\n\n\nSommer, L. (2022, February 9). An unexpected item is blocking cities’ climate change prep: Obsolete rainfall records. NPR: Climate. Retrieved from https://www.npr.org/2022/02/09/1078261183/an-unexpected-item-is-blocking-cities-climate-change-prep-obsolete-rainfall-reco"
  },
  {
    "objectID": "readings/week-14-reading.html",
    "href": "readings/week-14-reading.html",
    "title": "Readings for Week 14",
    "section": "",
    "text": "Discussion questions will be posted here.\n\n\n\nAssigned reading will be drawn from:\n\nKeller et al. (2021)\nGilligan & Vandenbergh (2020)\n\n\n\n\n\nReferences\n\nGilligan, J. M., & Vandenbergh, M. P. (2020). Beyond wickedness: Managing complex systems and climate change. Vanderbilt Law Review, 73, 1777–1810. Retrieved from https://wp0.vanderbilt.edu/lawreview/2020/12/beyond-wickedness-managing-complex-systems-and-climate-change/\n\n\nKeller, K., Helgeson, C., & Srikrishnan, V. (2021). Climate risk management. Annual Review of Earth and Planetary Sciences, 49(1), 95–116. https://doi.org/10.1146/annurev-earth-080320-055847"
  },
  {
    "objectID": "readings/week-07-reading.html",
    "href": "readings/week-07-reading.html",
    "title": "Readings for Week 7",
    "section": "",
    "text": "Discussion questions will be posted here.\n\n\n\nAssigned reading will be drawn from:\n\nvan Berchum et al. (2019)\nSchwetschenau et al. (2023)\n\n\n\n\n\nReferences\n\nSchwetschenau, S. E., Kovankaya, Y., Elliott, M. A., Allaire, M., White, K. D., & Lall, U. (2023). Optimizing Scale for Decentralized Wastewater Treatment: A Tool to Address Failing Wastewater Infrastructure in the United States. ACS ES&T Engineering, 3(1), 1–14. https://doi.org/10.1021/acsestengg.2c00188\n\n\nvan Berchum, E. C., Mobley, W., Jonkman, S. N., Timmermans, J. S., Kwakkel, J. H., & Brody, S. D. (2019). Evaluation of flood risk reduction strategies through combinations of interventions. Journal of Flood Risk Management, 12(S2), e12506. https://doi.org/10.1111/jfr3.12506"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Climate variability and change pose threats to lives and livelihoods. These climate risks can be managed through the design and operation of infrastructure systems, as well as through disaster response and recovery. Decisions about how to develop and choose risk management strategies are often based on pure vibes, but occasionally rigorous quantitative analyses that make use of scientific information can inform them (we will focus on these cases). These analyses involve integrating knowledge from multiple disciplines to balance competing goals (objectives) under uncertainty.\nIn this course, you will learn climate science, uncertainty quantification, and decision analysis methods to support climate risk management. You will be assigned readings for every class that cover both methods and applications, and will work collaboratively to implement key concepts through programming problem sets. Active class participation is required. Methods covered include scenario analysis, exploratory modeling, cost-benefit analysis, single- and multi-objective policy search, reinforcement learning, deep uncertainty, robust decision making, and equitable decision making.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "",
    "text": "Climate variability and change pose threats to lives and livelihoods. These climate risks can be managed through the design and operation of infrastructure systems, as well as through disaster response and recovery. Decisions about how to develop and choose risk management strategies are often based on pure vibes, but occasionally rigorous quantitative analyses that make use of scientific information can inform them (we will focus on these cases). These analyses involve integrating knowledge from multiple disciplines to balance competing goals (objectives) under uncertainty.\nIn this course, you will learn climate science, uncertainty quantification, and decision analysis methods to support climate risk management. You will be assigned readings for every class that cover both methods and applications, and will work collaboratively to implement key concepts through programming problem sets. Active class participation is required. Methods covered include scenario analysis, exploratory modeling, cost-benefit analysis, single- and multi-objective policy search, reinforcement learning, deep uncertainty, robust decision making, and equitable decision making.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-information",
    "href": "syllabus.html#course-information",
    "title": "Syllabus",
    "section": "Course Information",
    "text": "Course Information\n\n\n\nInstructor\n\n James Doss-Gollin\n jdossgollin@rice.edu\n Ryon 215\n\n\n\n\nTA\nTBD\n\n\n\nMeetings\n\n MWF\n 11-11:50am\n TBD\n\n\n\n\n\nPrerequisites & Preparation\nThe following prerequisites are required:\n\nAn introductory course in probability and statistics, such as CEVE 313, is strictly required.\n\nIn addition, the following prerequisites are encouraged.\n\nSome exposure to Python, Julia, Matlab, R, or another programming language\nAdditional coursework in applied statistics\nLinear algebra (you should be comfortable with matrix notation and basic operations)\nOptimization (you should be comfortable writing down optimization problems)\n\nIf you are unsure whether your background gives you an adequate preparation for this course, please contact the instructor!\n\n\n\n\n\n\nWhat If My Skills Are Rusty?\n\n\n\nIf your programming, mathematics, or statistics skills are a little rusty, don’t worry! We will review concepts and build skills over the course of the semester.\n\n\n\n\nCourse Objectives\nAfter completing this course, you will be able to:\n\nEvaluate and describe the strengths and weaknesses of different approaches to modeling the impact of weather and climate hazards on critical systems.\nApply and critique methods for cost-benefit analysis, optimization, policy search, and stochastic control to climate adaptation problems.\nDescribe multiple frameworks for decision making under deep uncertainty.\nDecision analytical frameworks well suited to a particular problem and justify the choice.\n\n\n\nRequired Materials\nNo textbook is required for this course. All materials will be posted as open source on the course website or on Canvas.\nYou will regularly be assigned scientific papers to read. Where those are available through the Rice library, you will be expected to access them yourself. You are encouraged, though not required, to use Zotero (Rice students have free storage). See Fondren Library’s Resources for resources.\nYou will need a working laptop for this class. If you do not have access to a working laptop, or if you lose access during the semester, please email the instructor.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#a-community-of-learning",
    "href": "syllabus.html#a-community-of-learning",
    "title": "Syllabus",
    "section": "A Community of Learning",
    "text": "A Community of Learning\nRice’s core values are responsibility, integrity, community, and excellence. Our goal is to create a learning community aligned with these core values.\n\nCore Expectations\nCourse success involves a dual responsibility on the part of the instructor and the student.\n\n\nAs the instructor, my responsibility is to provide you with a structure and opportunity to learn. To this end, I commit to:\n\nprovide organized and focused lectures, in-class activities, and assignments;\nencourage students to regularly evaluate and provide feedback on the course;\nmanage the classroom atmosphere to promote learning;\nschedule sufficient out-of-class contact opportunities, such as office hours;\nallow adequate time for assignment completion;\nmake lecture materials, class policies, activities, and assignments accessible to students.\n\n\n\n\nStudents are responsible for their own learning in the course and should commit to:\n\nattending all lectures;\ndoing all required preparatory work before class;\nactively participating in online and in-class discussions;\nbeginning assignments and other work early; and\nattending office hours as needed.\n\n\n\n\n\n\n\n\n\nWhat If I’m Sick?\n\n\n\nPlease stay home if you’re feeling sick! This is beneficial for both for your own recovery and the health and safety of your classmates. We will also make any necessary arrangements for you to stay on top of the class material and if whatever is going on will negatively impact your grade, for example by causing you to be unable to submit an assignment on time.\n\n\n\n\nDiversity, Equity, and Inclusion\nRice is committed to building and maintaining an equitable and inclusive campus community. Diversity can refer to multiple ways that we identify ourselves, including but not limited to race, color, national origin, language, sex, disability, age, sexual orientation, gender identity, religion, creed, ancestry, belief, veteran status, or genetic information. Each of these diverse identities, along with many others not mentioned here, shape the perspectives our students, faculty, and staff bring to our campus. We, at Rice, will work to promote diversity, equity and inclusion not only because diversity fuels excellence and innovation, but because we want to pursue justice. We acknowledge our imperfections while we also fully commit to the work, inside and outside of our classrooms, of building and sustaining a campus community that increasingly embraces these core values.\nEach of us is responsible for creating a safer, more inclusive environment.\n\n\nAccommodation for Students with Disabilities\nIf you have a documented disability or other condition that may affect academic performance you should: 1) make sure this documentation is on file with the Disability Resource Center (Allen Center, Room 111 / adarice@rice.edu / x5841) to determine the accommodations you need; and 2) talk with me to discuss your accommodation needs.\n\n\nAccommodation for Scheduling Conflicts\nIf any of our class meetings conflict with your religious events, student athletics, or other non-negotiable scheduling conflict, please let me know ASAP so that we can make arrangements for you.\n\n\nMask Policies\nMasks are welcome but not required in the classroom. However, if a colleague (student, faculty, or staff) requests that others wear a mask, you are strongly encouraged to make them feel safe. Please do not ask someone making such a request to disclose their underlying medical condition. If for some reason you need your instructor or classmates to wear a mask, please let me know and I will communicate this to the class without disclosing your identity.\nThese policies may change over the course of the semester as the situation evolves.\n\n\nGetting Help\nYou can ask questions through Canvas Discussions and Office Hours. We will make an effort to respond to all Canvas discussion questions within 24 hours, though this won’t always be possible (travel, weekends, etc.). Please do not use email for questions about course content or labs, since other students may have related questions. You should use email for questions about personal matters, such as scheduling conflicts, accommodations, etc.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#academic-integrity",
    "href": "syllabus.html#academic-integrity",
    "title": "Syllabus",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nThis class is designed to encourage collaboration, and students are encouraged to discuss their work with other students. Engineering as a profession relies upon the honesty and integrity of its practitioners (see e.g. the American Society for Civil Engineers’ Code of Ethics). All work submitted must represent the students’ own work and understanding, whether individually or as a group (depending on the particulars of the assignment).\nIf you are ever unclear about academic integrity, please ask! Additionally, always err on the side of providing more information.)\n\nRice Honor Code\nMore specifically, all students will be held to the standards of the Rice Honor Code, a code that you pledged to honor when you matriculated at this institution. If you are unfamiliar with the details of this code and how it is administered, you should consult the Honor System Handbook at honor.rice.edu/honor-system-handbook/. This handbook outlines the University’s expectations for the integrity of your academic work, the procedures for resolving alleged violations of those expectations, and the rights and responsibilities of students and faculty members throughout the process.\n\n\nAI/ML Resource Policy\nLarge language models (LLMs), like GPT, are powerful tools for generating text that can be used for coding and doing data analysis. This is at once empowering (LLMs are powerful and can save you time) and risky (LLMs can make mistakes that are hard to detect).\nOur general view is that LLMs are powerful tools that you will encounter and use when you leave this classroom, so it’s important to learn how to use them responsibly and effectively. You are generally permitted to use LLMs in this course, but ultimately, you are responsible for guaranteeing, understanding, and interpreting your results. In particular:\n\nOne of the best applications of LLMs is to write code. This can help accelerate your workflow, especially when you are learning new syntax. However, LLMs can make bad decisions about how to structure your code, can introduce bugs, and can mislead you about what your code is doing. You are responsible for understanding and debugging your code, and for ensuring that it does what you intend it to do.\nLLMs should not be used to generate text that you submit as your own work. If you are assigned a writing assignment, the point is to stimulate your thought process, and you short-cut this if you ask a LLM to generate the response for you. This leads to shallow thinking! However, you may use tools including LLMs (but also Grammarly, spell-check, etc.) to help you edit your writing. This can sometimes be a fine line; it’s always better to ask if you’re not sure, and to disclose your use of these tools in your submission\n\nThe resources page has links to helpful ideas about LLMs and how to use them.\n\n\nPolicy on Web Posting of Course Materials\nUploading course materials to web sites is not an authorized use of the course material. Both the poster and the user are in violation of the university policy, which is actionable.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nYour final grade will be calculated as follow:\n\n\n\nCategory\nPoints (421)\nPoints (521)\n\n\n\n\nReading quizzes\n10\n10\n\n\nLabs\n10\n10\n\n\nTests\n40\n30\n\n\nProject\n30\n30\n\n\nReading Discussion\n0\n10\n\n\nReading Notes\n10\n10\n\n\n\n\nReading Quizzes\nThe purpose of assigning readings is to enhance class discussions. Students who are prepared for class enhance the learning experience for everyone and enable a collaborative group discussion. At the start of classes for which reading was assigned, expect a very short (5 minute) quiz covering basic concepts from the reading. You should be able to get all points on these readings if you have done the reading, even if you found key concepts challenging or confusing.\nYour lowest two reading quizzes will be dropped.\n\n\nLabs\nOn Fridays we will use class time for hands-on programming exercises (“labs”) to give you guided practice applying the concepts and methods from class. These labs will be announced on the course website ahead of time so anyone who is able can bring a laptop to class. These labs can be done in groups; if you cannot bring a laptop to class for whatever reason, you will be able to (and are encouraged to) work with other students, though you must turn in your own assignment for grading. All labs will cover either a set of programming tools or a case study.\nYour lowest two labs will be dropped.\n\n\nTests\nIn-class written exams will be given for each module of the course. Tests are designed to be straightforward and will cover key ideas from reading, as well as key terms and concepts from lecture and code interpretation related to labs.\n\n\nProject\nWe will build a case study related to house elevation over the course of the semester through weekly labs. Answers will be posted for each lab, so mistakes made in one lab do not pass to the next.\nFor a final project, you will be asked to incorporate additional concept(s) from the course into the case study. For example, you might improve the representation of additional sources of uncertainty, use a more sophisticated optimization algorithm, or change the objectives of the optimization problem.\nStudents enrolled in the 421 section (i.e., undergraduates) may work in small groups. Students enrolled in the 521 section (i.e., graduate students) must work individually.\n\n\nReading Discussion\nAll students enrolled in the 521 section (i.e., graduate students) will present one of the papers assigned to the class and lead a discussion.\n\nThis discussion should take 30-50 minutes.\nYou should sign up for a time by the second week of class.\nYou should meet with your instructor at least one week before your presentation to discuss the reading and your discussion plan.\n\nYou will be graded on the quality of your presentation, the depth of your understanding of the reading, and your ability to lead a discussion.\nStudents enrolled in the 421 section may choose to present a paper alone or in a group. If you choose to present a paper, you will be graded on the same scale as the 521 students.\n\n\nReading Notes\nAll students will act as “note-taker” for an in-class reading discussion. The note-taker will be responsible for taking notes on the discussion (following up from the recording as necessary), then adding them to the course website (through a Pull Request; guidance will be provided). These notes should summarize, rather than transcribe, the discussion, and identify key insights, questions, disagreements, and points of confusion.\nYou should sign up for a time by the second week of class. Groups may be permitted depending on enrollment.\n\n\nLate Work Policy\nLate projects will be subjected to a 10% penalty per day. Specifically, your grade will be multiplied \\(0.9^d\\) where \\(d\\) is the number of days late. Late labs will not be accepted so that solutions can be posted promptly.\nAs described above, your lowest two labs and reading quizzes will be dropped. This is intended to accommodate events like minor illnesses, travel to a conference, and other circumstances that may cause you to miss a lab or quiz. If a major circumstance arises (e.g., a death in the family, a serious illness, etc.) that causes you to miss an extended period of time, please contact the instructor to discuss accommodations.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#preliminary-schedule",
    "href": "syllabus.html#preliminary-schedule",
    "title": "Syllabus",
    "section": "Preliminary Schedule",
    "text": "Preliminary Schedule\nThe following schedule outlines our planned topics and readings for the semester. In general, we will use Mondays for lecture, Wednesdays for group discussion centered on readings, and Fridays for computational labs.\nThis schedule is subject to change. Updated versions will be posted on the Schedule page of the course website.\n\n\n\n\n\n\nNot all readings listed here will be assigned in full. Some may be assigned as optional reading and others may be assigned as excerpts.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nCourse Dates\nTopic\nReading\nExam / Project\n\n\n\n\n\nModule 1:\nIntroduction\n\n\n\n\n1\n1/8, 1/10, 1/12\nIntroduction to climate risk management\nFrank (2022), Loucks (2017) Ch. 1\n\n\n\n2\n1/17, 1/19\nScience of climate hazard\nSeneviratne et al. (2021), Lall et al. (2018)\n\n\n\n3\n1/22, 1/24, 1/26\nVulnerability, exposure, and impacts\nWing et al. (2020), Bonnafous et al. (2017)\n\n\n\n4\n1/29, 1/31, 2/2\nSystems\nReed et al. (2022),\nExam 1\n\n\n\nModule 2:\nDecision Analysis\n\n\n\n\n5\n2/5, 2/7, 2/8\nCost-benefit analysis\nArrow et al. (2013)\n\n\n\n6\n2/12, 2/14, 2/16\nScenario analysis\nBankes (1993)\nFinal Project: Proposal\n\n\n7\n2/19, 2/21, 2/23\nPolicy search and optimization\nvan Berchum et al. (2019), Schwetschenau et al. (2023)\n\n\n\n8\n2/26, 2/28, 3/1\nMultiobjective policy search\nZarekarizi et al. (2020)\n\n\n\n9\n3/4, 3/6, 3/8\nSequential decision problems\nHerman et al. (2020), Quinn et al. (2017), Fletcher et al. (2019), Sutton & Barto (2018)\n\n\n\n10\n3/18, 3/20, 3/22\nRobustness\nHerman et al. (2015), McPhail et al. (2019)\nRevised Project Proposal; Exam 2\n\n\n\nModule 3:\nThinking Critically\n\n\n\n\n11\n3/25, 3/27, 3/29\nDeep uncertainty\nSchneider (2002), Lempert & Schlesinger (2000), Oreskes et al. (1994)\n\n\n\n12\n4/1, 4/3, 4/5\nEquity and justice\nPollack et al. (2023), Fletcher et al. (2022)\n\n\n\n13\n4/10, 4/12\nFinancial and systemic risks\nThomson et al. (2023), Condon (2021)\n\n\n\n14\n4/15, 4/17, 4/19\nReflections\nKeller et al. (2021), Gilligan & Vandenbergh (2020)\nDraft Project Writeup; Exam 3\n\n\n\n\nFinal Projects\n\n\n\n\n\nTBD\nduring final exam slot\n\nProject presentations\n\n\n\n4/30\n\n\nFinal write-up",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#references",
    "href": "syllabus.html#references",
    "title": "Syllabus",
    "section": "References",
    "text": "References\n\n\nArrow, K., Cropper, M., Gollier, C., Groom, B., Heal, G., Newell, R., et al. (2013). Determining benefits and costs for future generations. Science, 341(6144), 349–350. https://doi.org/10.1126/science.1235665\n\n\nBankes, S. (1993). Exploratory modeling for policy analysis. Operations Research, 41(3), 435–449. https://doi.org/c7rgcr\n\n\nBonnafous, L., Lall, U., & Siegel, J. (2017). A water risk index for portfolio exposure to climatic extremes: Conceptualization and an application to the mining industry. Hydrology and Earth System Sciences, 21(4), 2075–2106. https://doi.org/f96k67\n\n\nCondon, M. (2021). Market myopia’s climate bubble. https://doi.org/10.2139/ssrn.3782675\n\n\nFletcher, S., Lickley, M., & Strzepek, K. (2019). Learning about climate change uncertainty enables flexible water infrastructure planning. Nature Communications, 10(1), 1782. https://doi.org/10.1038/s41467-019-09677-x\n\n\nFletcher, S., Hadjimichael, A., Quinn, J., Osman, K., Giuliani, M., Gold, D., et al. (2022). Equity in Water Resources Planning: A Path Forward for Decision Support Modelers. Journal of Water Resources Planning and Management, 148(7), 02522005. https://doi.org/10.1061/(ASCE)WR.1943-5452.0001573\n\n\nFrank, T. (2022, August 22). Bold New Jersey Shore Flood Rules Could Be Blueprint for Entire U.S. Coast. Scientific American. Retrieved from https://www.scientificamerican.com/article/bold-new-jersey-shore-flood-rules-could-be-blueprint-for-entire-u-s-coast/\n\n\nGilligan, J. M., & Vandenbergh, M. P. (2020). Beyond wickedness: Managing complex systems and climate change. Vanderbilt Law Review, 73, 1777–1810. Retrieved from https://wp0.vanderbilt.edu/lawreview/2020/12/beyond-wickedness-managing-complex-systems-and-climate-change/\n\n\nHerman, J. D., Reed, P. M., Zeff, H. B., & Characklis, G. W. (2015). How should robustness be defined for water systems planning under change? Journal of Water Resources Planning and Management, 141(10), 04015012. https://doi.org/10.1061/(asce)wr.1943-5452.0000509\n\n\nHerman, J. D., Quinn, J. D., Steinschneider, S., Giuliani, M., & Fletcher, S. (2020). Climate adaptation as a control problem: Review and perspectives on dynamic water resources planning under uncertainty. Water Resources Research, e24389. https://doi.org/10.1029/2019wr025502\n\n\nKeller, K., Helgeson, C., & Srikrishnan, V. (2021). Climate risk management. Annual Review of Earth and Planetary Sciences, 49(1), 95–116. https://doi.org/10.1146/annurev-earth-080320-055847\n\n\nLall, U., Johnson, T., Colohan, P., Aghakouchak, A., Arumugam, S., Brown, C., et al. (2018). Chapter 3: Water. In D. R. Reidmiller, D. R. Easterling, K. E. Kunkel, K. L. M. Lewis, T. K. Maycock, & B. C. Stewart, Impacts, Risks, and Adaptation in the United States: The Fourth National Climate Assessment, Volume II. Washington, D.C.: U.S. Global Change Research Program. https://doi.org/10.7930/NCA4.2018.CH3\n\n\nLempert, R. J., & Schlesinger, M. E. (2000). Robust strategies for abating climate change. Climatic Change, 45(3-4), 387–401. https://doi.org/10.1023/A:1005698407365\n\n\nLoucks, D. P. (2017). Water resource systems planning and management: An introduction to methods, models, and applications. Cham: Imprint: Springer.\n\n\nMcPhail, C., Maier, H. R., Kwakkel, J. H., Giuliani, M., Castelletti, A., & Westra, S. (2019). Robustness metrics: How are they calculated, when should they be used and why do they give different results? Earth’s Future, 169–191. https://doi.org/10.1002/2017ef000649\n\n\nOreskes, N., Shrader-Frechette, K., & Belitz, K. (1994). Verification, validation, and confirmation of numerical models in the Earth sciences. Science. https://doi.org/10.1126/science.263.5147.641\n\n\nPollack, A., Helgeson, C., Kousky, C., & Keller, K. (2023, September 15). Transparency on underlying values is needed for useful equity measurements. https://doi.org/10.31219/osf.io/kvyxr\n\n\nQuinn, J. D., Reed, P. M., & Keller, K. (2017). Direct policy search for robust multi-objective management of deeply uncertain socio-ecological tipping points. Environmental Modelling & Software, 92, 125–141. https://doi.org/10.1016/j.envsoft.2017.02.017\n\n\nReed, P. M., Hadjimichael, A., Moss, R. H., Brelsford, C., Burleyson, C. D., Cohen, S., et al. (2022). Multisector Dynamics: Advancing the Science of Complex Adaptive Human-Earth Systems. Earth’s Future, 10(3), e2021EF002621. https://doi.org/10.1029/2021EF002621\n\n\nSchneider, S. H. (2002). Can we estimate the likelihood of climatic changes at 2100? Climatic Change, 52(4), 441–451. https://doi.org/http://dx.doi.org/10.1023/A:1014276210717\n\n\nSchwetschenau, S. E., Kovankaya, Y., Elliott, M. A., Allaire, M., White, K. D., & Lall, U. (2023). Optimizing Scale for Decentralized Wastewater Treatment: A Tool to Address Failing Wastewater Infrastructure in the United States. ACS ES&T Engineering, 3(1), 1–14. https://doi.org/10.1021/acsestengg.2c00188\n\n\nSeneviratne, S. I., Zhang, X., Adnan, M., Badi, W., Dereczynski, C., Di Luca, A., et al. (2021). Weather and climate extreme events in a changing climate. In V. Masson-Delmotte, P. Zhai, A. Pirani, S. L. Connors, C. Péan, S. Berger, et al. (Eds.), Climate change 2021: The physical science basis. Contribution of working group I to the sixth assessment report of the intergovernmental panel on climate change. Book section, Cambridge, UK and New York, NY, USA: Cambridge University Press. https://doi.org/10.1017/9781009157896.013\n\n\nSutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An Introduction (Second Edition). Cambridge, Massachusetts and London, England: MIT Press.\n\n\nThomson, H., Zeff, H. B., Kleiman, R., Sebastian, A., & Characklis, G. W. (2023). Systemic Financial Risk Arising From Residential Flood Losses. Earth’s Future, 11(4), e2022EF003206. https://doi.org/10.1029/2022EF003206\n\n\nvan Berchum, E. C., Mobley, W., Jonkman, S. N., Timmermans, J. S., Kwakkel, J. H., & Brody, S. D. (2019). Evaluation of flood risk reduction strategies through combinations of interventions. Journal of Flood Risk Management, 12(S2), e12506. https://doi.org/10.1111/jfr3.12506\n\n\nWing, O. E. J., Pinter, N., Bates, P. D., & Kousky, C. (2020). New insights into US flood vulnerability revealed from flood insurance big data. Nature Communications, 11(1, 1), 1444. https://doi.org/10.1038/s41467-020-15264-2\n\n\nZarekarizi, M., Srikrishnan, V., & Keller, K. (2020). Neglecting uncertainties biases house-elevation decisions to manage riverine flood risks. Nature Communications, 11(1, 1), 5361. https://doi.org/10.1038/s41467-020-19188-9",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "lectures/04-systems.html#references",
    "href": "lectures/04-systems.html#references",
    "title": "Climate Risks to Complex Sytems",
    "section": "References",
    "text": "References\n\n\nAmonkar, Y., Doss-Gollin, J., Farnham, D. J., Modi, V., & Lall, U. (2023). Differential effects of climate change on average and peak demand for heating and cooling across the contiguous USA. Communications Earth & Environment, 4(1, 1), 1–9. https://doi.org/10.1038/s43247-023-01048-1\n\n\nBusby, J. W., Baker, K., Bazilian, M. D., Gilbert, A. Q., Grubert, E., Rai, V., et al. (2021). Cascading risks: Understanding the 2021 winter blackout in Texas. Energy Research & Social Science, 77, 102106. https://doi.org/10.1016/j.erss.2021.102106\n\n\nDoss-Gollin, J., Farnham, D. J., Lall, U., & Modi, V. (2021). How unprecedented was the February 2021 Texas cold snap? Environmental Research Letters. https://doi.org/10.1088/1748-9326/ac0278\n\n\nDoss-Gollin, J., Amonkar, Y., Schmeltzer, K., & Cohan, D. (2023). Improving the representation of climate risks in long-term electricity systems planning: A critical review. Current Sustainable/Renewable Energy Reports. https://doi.org/10.1007/s40518-023-00224-3\n\n\nLee, J., & Dessler, A. E. (2022). The Impact of Neglecting Climate Change and Variability on ERCOT’s Forecasts of Electricity Demand in Texas. Weather, Climate, and Society, 14(2), 499–505. https://doi.org/10.1175/WCAS-D-21-0140.1\n\n\nReed, P. M., Hadjimichael, A., Moss, R. H., Brelsford, C., Burleyson, C. D., Cohen, S., et al. (2022). Multisector Dynamics: Advancing the Science of Complex Adaptive Human-Earth Systems. Earth’s Future, 10(3), e2021EF002621. https://doi.org/10.1029/2021EF002621"
  },
  {
    "objectID": "lectures/01-intro-class-topic.html#references",
    "href": "lectures/01-intro-class-topic.html#references",
    "title": "Welcome to CEVE 421/521!",
    "section": "References",
    "text": "References\n\n\nSatija, N., Collier, K., & Shaw, A. (2016, December 7). Boomtown, flood town. ProPublica: Hell and High Water. Retrieved from https://projects.propublica.org/houston-cypress/"
  },
  {
    "objectID": "lectures/03-vulnerability-exposure-impacts.html#references",
    "href": "lectures/03-vulnerability-exposure-impacts.html#references",
    "title": "Vulnerability, Exposure, and Impacts",
    "section": "Logistics",
    "text": "Logistics\n\nWednesday: discussion questions for Wing et al. (2020) posted\nWednesday after class: troubleshoot computing issues\nFriday: lab\n\n\n\n\n\n\n\n\n\nde Moel, H., van Vliet, M., & Aerts, J. C. J. H. (2014). Evaluating the effect of flood damage-reducing measures: A case study of the unembanked area of Rotterdam, the Netherlands. Regional Environmental Change, 14(3), 895–908. https://doi.org/10.1007/s10113-013-0420-z\n\n\nGidaris, I., Padgett, J. E., Barbosa, A. R., Chen, S., Cox, D., Webb, B., & Cerato, A. (2017). Multiple-Hazard Fragility and Restoration Models of Highway Bridges for Regional Risk and Resilience Assessment in the United States: State-of-the-Art Review. Journal of Structural Engineering, 143(3), 04016188. https://doi.org/10.1061/(ASCE)ST.1943-541X.0001672\n\n\nJongman, B., Ward, P. J., & Aerts, J. C. J. H. (2012). Global exposure to river and coastal flooding: Long term trends and changes. Global Environmental Change, 22(4), 823–835. https://doi.org/10.1016/j.gloenvcha.2012.07.004\n\n\nTedesco, M., McAlpine, S., & Porter, J. R. (2020). Exposure of real estate properties to the 2018 Hurricane Florence flooding. Natural Hazards and Earth System Sciences, 20(3), 907–920. https://doi.org/10.5194/nhess-20-907-2020\n\n\nWing, O. E. J., Pinter, N., Bates, P. D., & Kousky, C. (2020). New insights into US flood vulnerability revealed from flood insurance big data. Nature Communications, 11(1, 1), 1444. https://doi.org/10.1038/s41467-020-15264-2"
  },
  {
    "objectID": "lectures/05-bca.html",
    "href": "lectures/05-bca.html",
    "title": "Cost-Benefit Analysis",
    "section": "",
    "text": "We often want a quantitative way to compare two or more decisions. Hence, cost-benefit analysis.\nIt’s a simple idea. For a given “decision” (being deliberately vague about what we mean by this), we need some function that tells us how good or bad the decision is. Then, we can compare the goodness of different decisions.\n\n\n\n\n\n\nAs a motivating example, consider that we are have been asked to help a homeowner decide whether to elevate their home by 5ft to protect against future flooding, or whether to leave it as-is.\n\n\n\n\n\n\n\n\n\nFigure 1: Floodproofing in Houston, TX (Houston Public Media)"
  },
  {
    "objectID": "lectures/05-bca.html#dealing-with-time",
    "href": "lectures/05-bca.html#dealing-with-time",
    "title": "Cost-Benefit Analysis",
    "section": "Dealing with time",
    "text": "Dealing with time\nA key feature of nearly all climate adaptation problems is that costs and benefits are spread out over time. How should we weigh costs and benefits that occur at different times?\n\n\n\n\n\n\nFor example, the up-front cost of elevating a house is a cost that occurs now, while the benefits of reduced flood risk occur in the future.\n\n\n\nThe most common way to deal with this is to use net present value (NPV). The idea is to discount future costs and benefits to the present day. If our discount rate is \\(\\gamma = 2\\% = 0.02\\), then we care about a dollar of benefits in one year the same as we care about 98 cents today. More generally, if we have a discount rate of \\(\\gamma\\) then a dollar of benefits in \\(t\\) years is worth \\((1 - \\gamma) ^ t\\) today.\nThe net present value of a decision is the sum of the present values of all costs and benefits: \\[\nNPV = \\sum_{t=0}^T (1 - \\gamma)^t u(a, \\mathbf{s}_t)\n\\] where \\(T\\) is the time horizon of the decision. Note that we write \\(\\mathbf{s}_t\\) to indicate that the state of the world might have time-dependent variables."
  },
  {
    "objectID": "lectures/05-bca.html#cost-benefit-analysis-in-the-real-world",
    "href": "lectures/05-bca.html#cost-benefit-analysis-in-the-real-world",
    "title": "Cost-Benefit Analysis",
    "section": "Cost-benefit analysis in the real world",
    "text": "Cost-benefit analysis in the real world\nCost-benefit analysis is everywhere! Companies use it to decide whether to invest in new products or technologies, governments use it to decide whether to build new infrastructure or regulate pollution, and much more!\nA standard approach is:\n\nCome up with a state of the world \\(\\mathbf{s}\\) that represents your uncertainties.\nWrite down a utility function \\(u(a, \\mathbf{s})\\) that represents your preferences.\nChoose a discount rate \\(\\gamma\\)\nCalculate the net present value of each decision\nPick the decision with the highest net present value"
  },
  {
    "objectID": "lectures/05-bca.html#critiques-and-limitations",
    "href": "lectures/05-bca.html#critiques-and-limitations",
    "title": "Cost-Benefit Analysis",
    "section": "Critiques and limitations",
    "text": "Critiques and limitations\n\nSimple idea:\n\nAdd up all the costs\nAdd up all the benefits\n\nSometimes it’s hard to combine different things that we care about into a single number!\n\nCost and safety\nImpacts on different groups of people\nWe will revisit this in the context of multi-criteria decision analysis.\n\nIn practice, this often leads us to care only about costs and benefits that are easy to quantify / monetize\n\nValue of ecosystems?\n\nThe limitations of discounting are especially relevant for some types of climate adaptation decisions\n\nWe will revisit this on Wednesday\n\nWe often deal with “deep” uncertainties for which it’s hard to come up with a probability distribution\n\nWe will revisit this much later in the semester\n\nIs Bayesian decision theory a good model of how people actually make decisions?\n\nThis framework was largely formalized by Savage (1954), who postulated that people often behave as though maximizing expected utility\nEllsberg (1961) and others: this is not how people really make decisions!\nOur goal is to support decision-making, not predict how people will actually make decisions. So the fact that this is not how people actually make decisions is not a problem for us.\nThat said: when our predictions of “what is rational” diverge from what people actually do, we should be curious about why instead of assuming they are stupid!"
  },
  {
    "objectID": "lectures/05-bca.html#a-defense",
    "href": "lectures/05-bca.html#a-defense",
    "title": "Cost-Benefit Analysis",
    "section": "A defense",
    "text": "A defense\nCost-benefit analysis is still useful when applied thoughtfully.\n\nIt forces us to be explicit about our assumptions\n\nWhat we care about and how we are measuring it\nWhat we are ignoring\nHow we think about uncertainty\n\nAllows an apples-to-apples comparison of different decisions\n\nUltimately, cost-benefit analysis is a great decision-support tool, but it is not a decision-making tool. When applied well, it’s an iterative process through which we repeatedly refine our understanding of the decision problem. When applied poorly, it’s a black-box process that spits out a number that is used to justify a decision that was already made."
  },
  {
    "objectID": "lectures/05-bca.html#wednesday",
    "href": "lectures/05-bca.html#wednesday",
    "title": "Cost-Benefit Analysis",
    "section": "Wednesday",
    "text": "Wednesday\nDigging a bit deeper:\n\nDiscount rates for problems with long time horizons (Arrow et al., 2013)\nApplications of cost-benefit analysis\n\nSocial cost of carbon\nArmy Corps of Engineers projects\nEPA regulations"
  },
  {
    "objectID": "lectures/05-bca.html#thursday",
    "href": "lectures/05-bca.html#thursday",
    "title": "Cost-Benefit Analysis",
    "section": "Thursday",
    "text": "Thursday\nLab: implementing a simple cost-benefit analysis for house elevation."
  },
  {
    "objectID": "lectures/02-climate-hazard.html#references",
    "href": "lectures/02-climate-hazard.html#references",
    "title": "The Science of Climate Hazard",
    "section": "References",
    "text": "References\n\n\nLall, U., Johnson, T., Colohan, P., Aghakouchak, A., Arumugam, S., Brown, C., et al. (2018). Chapter 3: Water. In D. R. Reidmiller, D. R. Easterling, K. E. Kunkel, K. L. M. Lewis, T. K. Maycock, & B. C. Stewart, Impacts, Risks, and Adaptation in the United States: The Fourth National Climate Assessment, Volume II. Washington, D.C.: U.S. Global Change Research Program. https://doi.org/10.7930/NCA4.2018.CH3\n\n\nSeneviratne, S. I., Zhang, X., Adnan, M., Badi, W., Dereczynski, C., Di Luca, A., et al. (2021). Weather and climate extreme events in a changing climate. In V. Masson-Delmotte, P. Zhai, A. Pirani, S. L. Connors, C. Péan, S. Berger, et al. (Eds.), Climate change 2021: The physical science basis. Contribution of working group I to the sixth assessment report of the intergovernmental panel on climate change. Book section, Cambridge, UK and New York, NY, USA: Cambridge University Press. https://doi.org/10.1017/9781009157896.013"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Helpful Resources",
    "section": "",
    "text": "This page contains links to resources that may be helpful for the course. If you have a resource that you think would be helpful to others, please let me know and I will add it to the list.",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#julia",
    "href": "resources.html#julia",
    "title": "Helpful Resources",
    "section": "Julia",
    "text": "Julia\nThere are lots of great resources on programming and Julia. Here is a curated list of some particularly helpful tools.\n\n\n\n\n\n\nSome of these tutorials provide their own instructions on how to install Julia. Please follow the instructions provided in this course!\n\n\n\n\nGetting Started\n\nJulia for Nervous Begineers: A free course on JuliaAcademy for people who are hesitant but curious about learning to write code in Julia.\nFastTrack to Julia cheatsheet\nComprehensive Julia Tutorials: YouTube playlist covering a variety of Julia topics, starting with an introduciton to the language.\nMatlab-Python-Julia Cheatsheet\n\n\n\nDigging Deeper\n\nIntroduction to Computational Thinking: a great Julia-based course at MIT covering applied mathematics and computational thinking\n\n\n\nPlotting with Makie\n\nMakie Tutorials\nMakieCon 2023 YouTube Channel",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#other-software-tools",
    "href": "resources.html#other-software-tools",
    "title": "Helpful Resources",
    "section": "Other Software Tools",
    "text": "Other Software Tools\n\nGit and GitHub\n\nGit Basics from The Odin Project.\nLearn Git Branching: An interactive, visual tutorial to how git works.\nVersion Control from MIT’s “CS: Your Missing Semester” course.\nGit and GitHub for Poets: YouTube playlist covering the basics of git and GitHub.\nVersion Control with Git course from Software Carpentry\n\n\n\nZotero\n\nZotero and Citation Management by Fondren library\nZotero Quick Start Guide\n\n\n\nTypesetting Math\n\nJustin Bois’ tutorial.\nMarkdown Cheatsheet\nLaTeX Cheatsheet\nMathpix Snip allows you to convert images of equations to LaTeX code (there is a free tier)\nDetexify lets you draw a symbol and suggests the LaTeX code for the corresponding symbol",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#big-picture",
    "href": "resources.html#big-picture",
    "title": "Helpful Resources",
    "section": "Big Picture",
    "text": "Big Picture\n\nUsing Large Language Models (LLMs)\n\nGitHub Copilot is an extension for VS Code that can provide suggestions for code completion and editing. It is free for students and educators.\nBlog: “Bob Carpenter thinks GPT-4 is awesome”: this post highlights how GPT-4 is able to write a program in Stan, a statistical programming language, and also the mistakes that it makes. Finding and correcting these mistakes requires knowing the Stan language and having a deep understanding of the statistical model, but someone with this expertise could potentially use GPT-4 to accelerate their coding workflow. The comments are also interesting and insightful.\nAI Snake Oil is a blog that seeks to dispel hype, remove misconceptions, and clarify the limits of AI. The authors are in the Princeton University Department of Computer Science.\nChatGPT has both free and paid tiers and can be helpful with writing and interpreting code, though care is needed as described above",
    "crumbs": [
      "Resources"
    ]
  }
]